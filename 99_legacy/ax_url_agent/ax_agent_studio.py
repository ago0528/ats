import streamlit as st
import pandas as pd
import time
import os
import json
from dataclasses import asdict
from pathlib import Path
import re

# ax_url_agent.pyê°€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆë‹¤ê³  ê°€ì •í•˜ê³  ì„í¬íŠ¸
# ì‹¤ì œ ìš´ì˜ ì‹œì—ëŠ” íŒ¨í‚¤ì§€ êµ¬ì¡°ì— ë§ì¶° ì¡°ì • í•„ìš”
try:
    # ê¸°ì¡´ `ax_url_agent.py`ê°€ ì¸ì½”ë”©/ë¬¸ì ì†ìƒìœ¼ë¡œ SyntaxErrorë¥¼ ìœ ë°œí•  ìˆ˜ ìˆì–´,
    # Studioì—ì„œëŠ” "ì •ìƒ UTF-8" ëª¨ë“ˆì¸ `ax_url_agent_clean.py`ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.
    from ax_url_agent_clean import AXNavigationPipeline, NavigationPipelineResponse
except ImportError:
    st.error("ax_url_agent.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°™ì€ ë””ë ‰í† ë¦¬ì— ìœ„ì¹˜ì‹œì¼œ ì£¼ì„¸ìš”.")
    st.stop()

# ì±„íŒ… UX ë³´ì¡° ëª¨ë“ˆ (ê°™ì€ ë””ë ‰í† ë¦¬ì— ìœ„ì¹˜)
try:
    from chat_storage_jsonl import JSONLChatStore, ChatMessageRecord, ChatSummaryRecord
    from chat_memory_langchain import build_conversation_history_text, build_orchestrator_history_text, dataclass_to_dict
    from chat_llm_utils import condense_to_standalone_query, summarize_conversation_memory
except ImportError:
    JSONLChatStore = None  # type: ignore[assignment]
    ChatMessageRecord = None  # type: ignore[assignment]
    ChatSummaryRecord = None  # type: ignore[assignment]
    build_conversation_history_text = None  # type: ignore[assignment]
    build_orchestrator_history_text = None  # type: ignore[assignment]
    dataclass_to_dict = None  # type: ignore[assignment]
    condense_to_standalone_query = None  # type: ignore[assignment]
    summarize_conversation_memory = None  # type: ignore[assignment]

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="AX Agent Eval Studio",
    page_icon="ğŸ§ª",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í„°ë§ˆì´ì§•
st.markdown("""
<style>
    .stProgress .st-bo {
        background-color: #00c0f2;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        text-align: center;
    }
    .status-ok { color: green; font-weight: bold; }
    .status-error { color: red; font-weight: bold; }
    .status-warning { color: orange; font-weight: bold; }
</style>
""", unsafe_allow_html=True)

# ì‚¬ì´ë“œë°” ì„¤ì • (LNB)
with st.sidebar:
    st.title("ğŸ§ª AX Agent Studio")
    st.caption("v1.0.0 | Orchestrator & URL/WIKI Agent")
    
    st.divider()
    
    # 1. ëª¨ë¸ ë° í™˜ê²½ ì„¤ì •
    st.subheader("âš™ï¸ í™˜ê²½ ì„¤ì •")
    
    # API Key ì„¤ì • (í™˜ê²½ë³€ìˆ˜ ì—†ìœ¼ë©´ ì…ë ¥ë°›ê¸°)
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        api_key = st.text_input("OpenAI API Key", type="password")
        if not api_key:
            st.warning("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.stop()
    
    model_name = st.selectbox(
        "ì‚¬ìš© ëª¨ë¸",
        ["gpt-5.2", "gpt-5.1", "gpt-5.1-mini"],
        index=0
    )
    
    plan_id = st.text_input("Plan ID (Testìš©)", value="12345")
    
    st.divider()
    
    # 2. ì‹¤í–‰ ì˜µì…˜
    st.subheader("ğŸš€ ì‹¤í–‰ ì˜µì…˜")
    direct_url_agent = st.checkbox("Orchestrator ìƒëµ (URL Agent ì§ì ‘ í˜¸ì¶œ)", value=False)
    verbose_mode = st.checkbox("ìƒì„¸ ë¡œê·¸ í‘œì‹œ", value=True)

    st.divider()
    st.info("ğŸ’¡ íŒ: 'í”„ë¡¬í”„íŠ¸' íƒ­ì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•˜ê³  í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ë©”ì¸ íƒ€ì´í‹€
st.title("AX Agent Evaluation Studio")
st.markdown("Orchestrator ë° URL/WIKI Agentì˜ **ì‘ë‹µ í’ˆì§ˆ**ê³¼ **Latency**ë¥¼ ì¶”ì í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.")

# íƒ­ êµ¬ì„±
tab_exec, tab_analytics, tab_prompt, tab_chat = st.tabs(["ğŸ“Š ì‹¤í–‰ ë° ê²°ê³¼", "ğŸ“ˆ ì„±ëŠ¥ ë¶„ì„", "ğŸ“ í”„ë¡¬í”„íŠ¸ íŠœë‹", "ğŸ’¬ ì±„íŒ…"])

# -----------------------------------------------------------------------------
# 1. ì‹¤í–‰ ë° ê²°ê³¼ íƒ­
# -----------------------------------------------------------------------------
with tab_exec:
    col_input, col_result = st.columns([1, 1.5])
    
    # [Left] ì…ë ¥ ë° ì„¤ì •
    with col_input:
        st.subheader("1. ì§ˆì˜ ì…ë ¥")
        
        input_method = st.radio("ì…ë ¥ ë°©ì‹", ["ì§ì ‘ ì…ë ¥", "íŒŒì¼ ì—…ë¡œë“œ (.txt, .md)"])
        
        queries = []
        
        if input_method == "ì§ì ‘ ì…ë ¥":
            user_input = st.text_area("í…ŒìŠ¤íŠ¸í•  ì§ˆì˜ ì…ë ¥ (í•œ ì¤„ì— í•˜ë‚˜ì”©)", height=200, 
                                    placeholder="ì±„ìš© ë§Œë“¤ê³  ì‹¶ì–´\nì§€ì›ì ë³´ì—¬ì¤˜\n...")
            if user_input:
                queries = [line.strip() for line in user_input.split('\n') if line.strip()]
                
        else: # íŒŒì¼ ì—…ë¡œë“œ
            uploaded_file = st.file_uploader("í…ŒìŠ¤íŠ¸ íŒŒì¼ ì—…ë¡œë“œ", type=["txt", "md"])
            if uploaded_file:
                content = uploaded_file.read().decode("utf-8")
                
                if uploaded_file.name.endswith(".md"):
                    # MD íŒŒì¼ íŒŒì‹± (í‘œ í˜•íƒœ ê°€ì •)
                    for line in content.splitlines():
                        if re.match(r'^\| \d+ \|', line):
                            parts = line.split('|')
                            if len(parts) > 3:
                                queries.append(parts[3].strip())
                    st.success(f"Markdown í‘œì—ì„œ {len(queries)}ê°œì˜ ì§ˆì˜ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
                else:
                    # TXT íŒŒì¼ íŒŒì‹±
                    queries = [line.strip() for line in content.splitlines() if line.strip()]
                    st.success(f"í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ {len(queries)}ê°œì˜ ì§ˆì˜ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
        
        st.divider()
        
        # ì‹¤í–‰ ë²„íŠ¼
        run_btn = st.button("í…ŒìŠ¤íŠ¸ ì‹¤í–‰", type="primary", disabled=len(queries) == 0, width='stretch')
    
    # [Right] ì‹¤í–‰ ê²°ê³¼ ì‹¤ì‹œê°„ í‘œì‹œ
    with col_result:
        st.subheader("2. ì‹¤í–‰ ê²°ê³¼")
        
        if "results" not in st.session_state:
            st.session_state.results = []
            
        result_container = st.container()
        
        if run_btn:
            st.session_state.results = [] # ì´ˆê¸°í™”
            pipeline = AXNavigationPipeline(api_key=api_key, model=model_name)
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            total_queries = len(queries)
            
            for i, query in enumerate(queries):
                status_text.text(f"[{i+1}/{total_queries}] ë¶„ì„ ì¤‘: {query[:30]}...")
                
                # ì—ì´ì „íŠ¸ í˜¸ì¶œ
                try:
                    res = pipeline.recommend(
                        query=query,
                        plan_id=plan_id,
                        direct_url_agent=direct_url_agent
                    )
                    st.session_state.results.append(res)
                except Exception as e:
                    st.error(f"Error processing '{query}': {str(e)}")
                
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                progress_bar.progress((i + 1) / total_queries)
                
            status_text.text("ë¶„ì„ ì™„ë£Œ!")
            st.success(f"ì´ {total_queries}ê°œ ì§ˆì˜ ë¶„ì„ ì™„ë£Œ")
        
        # ê²°ê³¼ ë Œë”ë§ (ë°ì´í„°í”„ë ˆì„ ë³€í™˜)
        if st.session_state.results:
            data = []
            for r in st.session_state.results:
                
                # planId í‘œì‹œ ë¡œì§ (ax_url_agent.pyì™€ ë™ê¸°í™”)
                plan_id_display = "-"
                # ê¸°ì¡´ requires_plan_id ëŒ€ì‹  plan_id_required ì‚¬ìš©
                # NavigationPipelineResponse ê°ì²´ê°€ ìµœì‹  ìƒíƒœì¸ì§€ í™•ì¸ í•„ìš”
                # ë§Œì•½ ê°ì²´ ì†ì„±ëª…ì´ ì•„ì§ ì—…ë°ì´íŠ¸ ì•ˆ ëœ êµ¬ë²„ì „ íŒ¨í‚¤ì§€ë¥¼ ì“°ê³  ìˆë‹¤ë©´ ì—ëŸ¬ ë‚  ìˆ˜ ìˆìŒ
                # í•˜ì§€ë§Œ ë¡œì»¬ íŒŒì¼ importì´ë¯€ë¡œ ê´œì°®ìŒ.
                
                # ì•ˆì „í•˜ê²Œ ì†ì„± ì¡´ì¬ ì—¬ë¶€ ì²´í¬ (í˜¸í™˜ì„±)
                is_required = getattr(r, 'plan_id_required', getattr(r, 'requires_plan_id', False))
                pid_val = getattr(r, 'plan_id', None)
                
                if is_required:
                    plan_id_display = str(pid_val) if pid_val else "í•„ìš”(ë¯¸ì…ë ¥)"
                
                # WIKI Agent í•„ë“œ (í˜¸í™˜ì„± ê³ ë ¤: getattr ì‚¬ìš©)
                wiki_analyzed_q = getattr(r, "wiki_analyzed_query", None)
                wiki_analyzed_tag = getattr(r, "wiki_analyzed_tag", None)
                wiki_results_count = getattr(r, "wiki_search_results_count", None)
                wiki_answer = getattr(r, "wiki_answer", None) or ""
                wiki_answer_short = wiki_answer[:100] + "..." if len(wiki_answer) > 100 else (wiki_answer or "-")

                wiki_qa_latency = float(getattr(r, "wiki_query_analyzer_latency", 0.0) or 0.0)
                wiki_search_latency = float(getattr(r, "wiki_search_api_latency", 0.0) or 0.0)
                wiki_synth_latency = float(getattr(r, "wiki_synthesizer_latency", 0.0) or 0.0)
                wiki_total_latency = float(getattr(r, "wiki_agent_latency", 0.0) or 0.0)

                data.append({
                    "Query": r.query,
                    "Agent": r.selected_agent_id,
                    "URL": r.url,
                    "PlanID": plan_id_display,
                    "Latency (Total)": f"{r.total_latency:.2f}s",
                    "Orch Latency": f"{r.orchestrator_latency:.2f}s",
                    "URL Latency": f"{r.url_agent_latency:.2f}s",
                    "WIKI Latency": f"{wiki_total_latency:.2f}s" if r.selected_agent_id == "RECRUIT_WIKI_WORKER" else "-",
                    "WIKI QA Latency": f"{wiki_qa_latency:.2f}s" if r.selected_agent_id == "RECRUIT_WIKI_WORKER" else "-",
                    "WIKI Search Latency": f"{wiki_search_latency:.2f}s" if r.selected_agent_id == "RECRUIT_WIKI_WORKER" else "-",
                    "WIKI Synth Latency": f"{wiki_synth_latency:.2f}s" if r.selected_agent_id == "RECRUIT_WIKI_WORKER" else "-",
                    "WIKI q": wiki_analyzed_q if wiki_analyzed_q else ("-" if r.selected_agent_id != "RECRUIT_WIKI_WORKER" else ""),
                    "WIKI tag": wiki_analyzed_tag if wiki_analyzed_tag else ("-" if r.selected_agent_id != "RECRUIT_WIKI_WORKER" else ""),
                    "WIKI results": str(wiki_results_count) if wiki_results_count is not None else ("-" if r.selected_agent_id != "RECRUIT_WIKI_WORKER" else ""),
                    "WIKI answer": wiki_answer_short if r.selected_agent_id == "RECRUIT_WIKI_WORKER" else "-",
                    "Reason": f"{r.orchestrator_reason} / {r.url_reason}" if r.selected_agent_id == "URL_WORKER" else r.orchestrator_reason,
                    "Error": r.error if r.error else "-"
                })
            
            df = pd.DataFrame(data)
            
            # ìš”ì•½ ë©”íŠ¸ë¦­ í‘œì‹œ
            m1, m2, m3 = st.columns(3)
            # ë¬¸ìì—´ "0.12s" ì—ì„œ "s" ì œê±° í›„ float ë³€í™˜
            avg_latency = 0.0
            if not df.empty:
                avg_latency = df["Latency (Total)"].str.replace("s", "").astype(float).mean()
            
            error_count = df[df["Error"] != "-"].shape[0]
            
            m1.metric("í‰ê·  ì‘ë‹µ ì‹œê°„", f"{avg_latency:.2f}s")
            m2.metric("ì´ ì‹¤í–‰ ìˆ˜", len(df))
            m3.metric("ì—ëŸ¬ ë°œìƒ", error_count, delta_color="inverse")
            
            # ìƒì„¸ í…Œì´ë¸”
            st.dataframe(df, width='stretch', height=500)

            # ìƒì„¸ ê²°ê³¼ (ì„ íƒ ì‚¬í•­)
            if verbose_mode:
                st.divider()
                st.subheader("3. ìƒì„¸ ê²°ê³¼")
                for idx, r in enumerate(st.session_state.results, 1):
                    header = f"[{idx}] {r.selected_agent_id} | {r.query}"
                    with st.expander(header, expanded=False):
                        if r.error:
                            st.error(r.error)
                            continue

                        st.caption(f"Orchestrator Reason: {r.orchestrator_reason}")

                        if r.selected_agent_id == "URL_WORKER":
                            st.write(f"Matched Name: {r.matched_name}")
                            st.write(f"URL: {r.url}")
                            st.write(f"URL Reason: {r.url_reason}")

                        if r.selected_agent_id == "RECRUIT_WIKI_WORKER":
                            wiki_docs = getattr(r, "wiki_documents", None) or []
                            wiki_answer_full = (getattr(r, "wiki_answer", None) or "").replace("/n", "\n")
                            wiki_req_url = getattr(r, "wiki_search_api_request_url", None)
                            wiki_req_params = getattr(r, "wiki_search_api_request_params", None)
                            wiki_raw = getattr(r, "wiki_search_api_response_raw", None)

                            st.write(f"Analyzed q: {getattr(r, 'wiki_analyzed_query', '')}")
                            st.write(f"Analyzed tag: {getattr(r, 'wiki_analyzed_tag', '')}")

                            st.subheader("Search API ì¶”ì ")
                            if wiki_req_url:
                                st.write(f"Request URL: {wiki_req_url}")
                            if isinstance(wiki_req_params, dict):
                                st.write("Request Params:")
                                st.json(wiki_req_params)

                            show_raw = st.checkbox(
                                "Search API ì›ë³¸ Response(JSON) í‘œì‹œ(ìš©ëŸ‰ í¼)",
                                value=False,
                                key=f"show_wiki_raw_{idx}",
                            )
                            if show_raw:
                                if isinstance(wiki_raw, dict):
                                    st.json(wiki_raw)
                                else:
                                    st.info("ì›ë³¸ Responseë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                            st.subheader("ë‹µë³€")
                            st.text(wiki_answer_full if wiki_answer_full else "(ë‹µë³€ ì—†ìŒ)")

                            st.subheader("ê²€ìƒ‰ ë¬¸ì„œ")
                            if wiki_docs:
                                docs_rows = []
                                for d in wiki_docs:
                                    docs_rows.append({
                                        "title": d.get("title"),
                                        "score": d.get("score"),
                                        "url": d.get("url"),
                                        "tags": ", ".join(d.get("tags", [])) if isinstance(d.get("tags"), list) else d.get("tags"),
                                    })
                                st.dataframe(pd.DataFrame(docs_rows), width='stretch', height=240)
                            else:
                                st.info("ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                "ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                csv,
                "ax_agent_results.csv",
                "text/csv",
                key='download-csv'
            )

# -----------------------------------------------------------------------------
# 2. ì„±ëŠ¥ ë¶„ì„ íƒ­
# -----------------------------------------------------------------------------
with tab_analytics:
    st.header("ğŸ“ˆ ì„±ëŠ¥ ë° í’ˆì§ˆ ë¶„ì„")
    
    if not st.session_state.results:
        st.info("ë¨¼ì € 'ì‹¤í–‰ ë° ê²°ê³¼' íƒ­ì—ì„œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    else:
        df = pd.DataFrame([
            {
                "Agent": r.selected_agent_id, 
                "Latency": r.total_latency,
                "HasError": bool(r.error)
            } for r in st.session_state.results
        ])
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ì—ì´ì „íŠ¸ ì„ íƒ ë¶„í¬")
            if not df.empty:
                agent_counts = df["Agent"].value_counts()
                st.bar_chart(agent_counts)
            
        with col2:
            st.subheader("ì‘ë‹µ ì‹œê°„ ë¶„í¬ (Histogram)")
            if not df.empty:
                st.bar_chart(df["Latency"])

        st.divider()
        st.subheader("Slow Queries (Top 5)")
        
        if not df.empty:
            # ëŠë¦° ìˆœì„œëŒ€ë¡œ ì •ë ¬
            slow_queries = pd.DataFrame([
                {"Query": r.query, "Latency": r.total_latency, "Agent": r.selected_agent_id}
                for r in st.session_state.results
            ]).sort_values("Latency", ascending=False).head(5)
            
            st.table(slow_queries)

# -----------------------------------------------------------------------------
# 3. í”„ë¡¬í”„íŠ¸ íŠœë‹ íƒ­
# -----------------------------------------------------------------------------
with tab_prompt:
    st.header("ğŸ“ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ìƒŒë“œë°•ìŠ¤")
    
    current_dir = Path(__file__).parent
    prompt_root_dir = current_dir.parent / "prompt" / "nmrs_v14.1.0"

    prompt_orch_path = prompt_root_dir / "prompt_orchestrator_worker.md"
    prompt_url_path = prompt_root_dir / "prompt_url_worker.md"
    prompt_wiki_analyzer_path = prompt_root_dir / "prompt_wiki_worker_query_analyzer.md"
    prompt_wiki_synth_path = prompt_root_dir / "prompt_wiki_worker_synthesizer.md"

    col_p1, col_p2 = st.columns(2)
    
    with col_p1:
        st.subheader("Orchestrator Prompt")
        if prompt_orch_path.exists():
            orch_content = prompt_orch_path.read_text(encoding="utf-8")
            new_orch_content = st.text_area("í¸ì§‘", orch_content, height=400, key="orch_edit")
            if st.button("Orchestrator ì €ì¥", key="save_orch"):
                prompt_orch_path.write_text(new_orch_content, encoding="utf-8")
                st.success("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.error("prompt_orchestrator_worker.md íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    with col_p2:
        st.subheader("URL Agent Prompt")
        if prompt_url_path.exists():
            url_content = prompt_url_path.read_text(encoding="utf-8")
            new_url_content = st.text_area("í¸ì§‘", url_content, height=400, key="url_edit")
            if st.button("URL Agent ì €ì¥", key="save_url"):
                prompt_url_path.write_text(new_url_content, encoding="utf-8")
                st.success("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.error("prompt_url_worker.md íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    st.divider()
    col_p3, col_p4 = st.columns(2)

    with col_p3:
        st.subheader("WIKI Query Analyzer Prompt")
        if prompt_wiki_analyzer_path.exists():
            analyzer_content = prompt_wiki_analyzer_path.read_text(encoding="utf-8")
            new_analyzer_content = st.text_area("í¸ì§‘", analyzer_content, height=400, key="wiki_analyzer_edit")
            if st.button("WIKI Query Analyzer ì €ì¥", key="save_wiki_analyzer"):
                prompt_wiki_analyzer_path.write_text(new_analyzer_content, encoding="utf-8")
                st.success("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.error("prompt_wiki_worker_query_analyzer.md íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    with col_p4:
        st.subheader("WIKI Synthesizer Prompt")
        if prompt_wiki_synth_path.exists():
            synth_content = prompt_wiki_synth_path.read_text(encoding="utf-8")
            new_synth_content = st.text_area("í¸ì§‘", synth_content, height=400, key="wiki_synth_edit")
            if st.button("WIKI Synthesizer ì €ì¥", key="save_wiki_synth"):
                prompt_wiki_synth_path.write_text(new_synth_content, encoding="utf-8")
                st.success("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.error("prompt_wiki_worker_synthesizer.md íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# -----------------------------------------------------------------------------
# 4. ì±„íŒ… íƒ­ (ì‚¬ìš©ì ê´€ì  UX í…ŒìŠ¤íŠ¸)
# -----------------------------------------------------------------------------
with tab_chat:
    st.header("ğŸ’¬ ì±„íŒ… UX í…ŒìŠ¤íŠ¸")
    st.caption("ëŒ€í™” ë§¥ë½(ë©”ëª¨ë¦¬)ì„ ìœ ì§€í•˜ë©° AX Agentë¥¼ ì‚¬ìš©ì ê´€ì ì—ì„œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")

    if JSONLChatStore is None:
        st.error("ì±„íŒ… ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. chat_storage_jsonl.py ë“±ì´ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    current_dir = Path(__file__).parent
    chat_root_dir = current_dir / ".chat_history"
    store = JSONLChatStore(chat_root_dir)

    # -----------------------------
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    # -----------------------------
    if "chat_conversation_id" not in st.session_state:
        existing = store.list_conversations()
        st.session_state.chat_conversation_id = existing[0] if existing else store.new_conversation_id()

    if "chat_messages" not in st.session_state:
        st.session_state.chat_messages = []

    if "chat_summary" not in st.session_state:
        st.session_state.chat_summary = None

    # -----------------------------
    # ëŒ€í™”ë°© ì»¨íŠ¸ë¡¤ + ì„¤ì •
    # -----------------------------
    col_ctrl, col_chat = st.columns([1, 1.6])

    with col_ctrl:
        st.subheader("ëŒ€í™”ë°©")

        conversations = store.list_conversations()
        # ì•„ì§ ì €ì¥ëœ ëŒ€í™”ê°€ í•˜ë‚˜ë„ ì—†ëŠ” ê²½ìš°ì—ë„ ì„ íƒ UIê°€ ë™ì‘í•´ì•¼ í•œë‹¤.
        if st.session_state.chat_conversation_id not in conversations:
            conversations = [st.session_state.chat_conversation_id] + conversations

        selected = st.selectbox(
            "ì„ íƒ",
            options=conversations,
            index=conversations.index(st.session_state.chat_conversation_id) if st.session_state.chat_conversation_id in conversations else 0,
            key="chat_conversation_select",
        )

        def _load_conversation(conversation_id: str) -> None:
            msgs, summ = store.load_messages(conversation_id)
            st.session_state.chat_conversation_id = conversation_id
            st.session_state.chat_messages = msgs
            st.session_state.chat_summary = summ

        if selected != st.session_state.chat_conversation_id:
            _load_conversation(selected)

        col_btn1, col_btn2 = st.columns(2)
        with col_btn1:
            if st.button("ìƒˆ ëŒ€í™”", width='stretch'):
                new_id = store.new_conversation_id()
                _load_conversation(new_id)
                st.rerun()

        with col_btn2:
            confirm_delete = st.checkbox("ì‚­ì œ í™•ì¸", value=False, key="chat_confirm_delete")
            if st.button("ì‚­ì œ", width='stretch', disabled=not confirm_delete):
                store.delete_conversation(st.session_state.chat_conversation_id)
                # ì‚­ì œ í›„ì—ëŠ” ê°€ì¥ ìµœì‹  ëŒ€í™”ë¡œ ì´ë™
                remaining = store.list_conversations()
                fallback = remaining[0] if remaining else store.new_conversation_id()
                _load_conversation(fallback)
                st.rerun()

        st.divider()

        st.subheader("ë©”ëª¨ë¦¬/ë””ë²„ê·¸")
        debug_mode = st.checkbox("ë””ë²„ê·¸ í‘œì‹œ", value=True, key="chat_debug_mode")
        max_history_messages = st.slider("íˆìŠ¤í† ë¦¬ ë©”ì‹œì§€ ìˆ˜", min_value=4, max_value=40, value=12, step=2)
        auto_summary = st.checkbox("ìë™ ìš”ì•½(ë©”ëª¨ë¦¬) ì—…ë°ì´íŠ¸", value=False, key="chat_auto_summary")
        summary_trigger_messages = st.slider("ìš”ì•½ íŠ¸ë¦¬ê±°(ë©”ì‹œì§€ ìˆ˜)", min_value=10, max_value=80, value=24, step=2)

        if st.session_state.chat_summary and st.session_state.chat_summary.content:
            st.text_area("í˜„ì¬ ìš”ì•½", st.session_state.chat_summary.content, height=160, key="chat_summary_view", disabled=True)
        else:
            st.caption("ìš”ì•½ì´ ì—†ë‹¤. ìë™ ìš”ì•½ì„ ì¼œê±°ë‚˜ ëŒ€í™”ë¥¼ ì¶©ë¶„íˆ ì§„í–‰í•˜ë©´ ìƒì„±í•  ìˆ˜ ìˆë‹¤.")

        # JSONL ë‹¤ìš´ë¡œë“œ
        conv_path = store.get_conversation_file_path(st.session_state.chat_conversation_id)
        if conv_path.exists():
            st.download_button(
                "ëŒ€í™” JSONL ë‹¤ìš´ë¡œë“œ",
                data=conv_path.read_bytes(),
                file_name=f"{st.session_state.chat_conversation_id}.jsonl",
                mime="application/jsonl",
                width='stretch',
            )

    # -----------------------------
    # ì±„íŒ… UI
    # -----------------------------
    with col_chat:
        st.subheader("ì±„íŒ…")

        # ë©”ì‹œì§€ ë Œë”ë§
        for m in st.session_state.chat_messages:
            role = (m.role or "assistant").strip().lower()
            if role not in ["user", "assistant"]:
                # system ë“±ì€ ì±„íŒ… ë¡œê·¸ì—ì„œ ìˆ¨ê¸´ë‹¤(í˜¼ë€ ë°©ì§€). í•„ìš”í•˜ë©´ ë””ë²„ê·¸ì—ì„œ í™•ì¸í•œë‹¤.
                continue

            with st.chat_message(role):
                st.markdown(m.content)
                if debug_mode and role == "assistant":
                    meta = getattr(m, "meta", None) or {}
                    if isinstance(meta, dict) and meta:
                        with st.expander("ë””ë²„ê·¸", expanded=False):
                            st.json(meta)

        # ì…ë ¥
        user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        if user_input:
            pipeline = AXNavigationPipeline(api_key=api_key, model=model_name)

            # í˜„ì¬ ëŒ€í™”ì˜ íˆìŠ¤í† ë¦¬ë¥¼ êµ¬ì„±í•œë‹¤.
            history_text = build_conversation_history_text(
                messages=st.session_state.chat_messages,
                summary=st.session_state.chat_summary,
                max_messages=max_history_messages,
                include_system=False,
            )

            # Orchestratorì—ëŠ” 'ë¼ìš°íŒ… ì¹œí™”' íˆìŠ¤í† ë¦¬ë¥¼ ì „ë‹¬í•œë‹¤.
            orchestrator_history_text = build_orchestrator_history_text(
                messages=st.session_state.chat_messages,
                summary=st.session_state.chat_summary,
                max_messages=max(max_history_messages, 12),
                include_system=False,
            )

            # ë‹¨ë… ì§ˆì˜ ì¬êµ¬ì„±
            condense_res = condense_to_standalone_query(
                api_key=api_key,
                model=model_name,
                history_text=history_text,
                user_input=user_input,
            )
            standalone_query = condense_res.text

            # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥(ì›ë³¸)
            user_record = ChatMessageRecord(
                conversation_id=st.session_state.chat_conversation_id,
                role="user",
                content=user_input,
                ts=time.time(),
                meta={
                    "standalone_query": standalone_query,
                    "condense_latency_s": condense_res.latency_s,
                    "condense_error": condense_res.error,
                },
            )
            store.append_message(user_record)
            st.session_state.chat_messages.append(user_record)

            # íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ (recommendëŠ” queryë¥¼ ë³„ë„ë¡œ ë°›ìœ¼ë¯€ë¡œ conversation_historyì—ëŠ” ì§ì „ íˆìŠ¤í† ë¦¬ë§Œ ì „ë‹¬í•œë‹¤)
            try:
                res = pipeline.recommend(
                    query=standalone_query,
                    plan_id=plan_id,
                    conversation_history=orchestrator_history_text,
                    direct_url_agent=direct_url_agent,
                )
            except Exception as e:
                # ì˜ˆì™¸ëŠ” ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ í‘œì‹œí•˜ê³ , ëŒ€í™”ëŠ” ì´ì–´ì§€ë„ë¡ í•œë‹¤.
                res = NavigationPipelineResponse(
                    query=standalone_query,
                    selected_agent_id="NONE",
                    orchestrator_reason="",
                    url="",
                    url_reason="",
                    matched_name="",
                    plan_id_required=False,
                    plan_id=None,
                    error=f"Pipeline í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}",
                    total_latency=0.0,
                    orchestrator_latency=0.0,
                    url_agent_latency=0.0,
                )

            # ì‚¬ìš©ì ê´€ì  ë‹µë³€ í…ìŠ¤íŠ¸ êµ¬ì„±
            if getattr(res, "error", None):
                assistant_text = f"ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆë‹¤.\n\n- ì˜¤ë¥˜: {res.error}"
            elif res.selected_agent_id == "URL_WORKER":
                pid_hint = ""
                if getattr(res, "plan_id_required", False):
                    pid_hint = f"\n\n- planId: {res.plan_id if res.plan_id else 'í•„ìš”(ë¯¸ì…ë ¥)'}"
                assistant_text = (
                    "ì´ë™í•  í˜ì´ì§€ë¥¼ ì°¾ì•˜ë‹¤.\n\n"
                    f"- URL: {res.url}\n"
                    f"- ê¸°ëŠ¥: {res.matched_name}\n"
                    f"- ì´ìœ : {res.url_reason}{pid_hint}"
                )
            elif res.selected_agent_id == "RECRUIT_WIKI_WORKER":
                answer = getattr(res, "wiki_answer", None) or ""
                assistant_text = answer.strip() if answer.strip() else "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ì§€ë§Œ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆë‹¤."
            else:
                # URL ì¶”ì²œì´ ì•„ë‹Œ ê²½ìš°ì—ë„ ì‚¬ìš©ìê°€ ë‹¤ìŒ í–‰ë™ì„ ì•Œ ìˆ˜ ìˆì–´ì•¼ í•œë‹¤.
                assistant_text = (
                    "ìš”ì²­ì„ ì²˜ë¦¬í•  ì›Œì»¤ë¥¼ ì„ íƒí–ˆë‹¤.\n\n"
                    f"- ì„ íƒ: {res.selected_agent_id}\n"
                    f"- ì´ìœ : {res.orchestrator_reason if res.orchestrator_reason else '(ì—†ìŒ)'}\n\n"
                    "í˜„ì¬ ìŠ¤íŠœë””ì˜¤ì—ì„œëŠ” URL/WIKI ì‘ë‹µë§Œ ì§ì ‘ ì‹¤í–‰í•œë‹¤."
                )

            assistant_meta = {
                "selected_agent_id": res.selected_agent_id,
                "standalone_query": standalone_query,
                "history_text_sent_to_orchestrator": orchestrator_history_text,
                "latency_s": {
                    "total": getattr(res, "total_latency", 0.0),
                    "orchestrator": getattr(res, "orchestrator_latency", 0.0),
                    "url_agent": getattr(res, "url_agent_latency", 0.0),
                    "wiki_agent": getattr(res, "wiki_agent_latency", 0.0),
                },
                "reason": {
                    "orchestrator": getattr(res, "orchestrator_reason", ""),
                    "url": getattr(res, "url_reason", ""),
                },
                "url": getattr(res, "url", ""),
                "matched_name": getattr(res, "matched_name", ""),
                "plan_id_required": getattr(res, "plan_id_required", False),
                "plan_id": getattr(res, "plan_id", None),
                "raw_response": dataclass_to_dict(res),
            }

            assistant_record = ChatMessageRecord(
                conversation_id=st.session_state.chat_conversation_id,
                role="assistant",
                content=assistant_text,
                ts=time.time(),
                meta=assistant_meta,
            )
            store.append_message(assistant_record)
            st.session_state.chat_messages.append(assistant_record)

            # ìë™ ìš”ì•½ ì—…ë°ì´íŠ¸(ì„ íƒ)
            if auto_summary and len(st.session_state.chat_messages) >= summary_trigger_messages:
                # ìš”ì•½ì€ ê¸´ íˆìŠ¤í† ë¦¬ë¥¼ ì••ì¶•í•˜ê¸° ìœ„í•œ ëª©ì ì´ë¯€ë¡œ, ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°±ì‹ í•œë‹¤.
                full_history_text = build_conversation_history_text(
                    messages=st.session_state.chat_messages,
                    summary=None,
                    max_messages=9999,
                    include_system=False,
                )
                existing_summary = st.session_state.chat_summary.content if st.session_state.chat_summary else ""
                summ_res = summarize_conversation_memory(
                    api_key=api_key,
                    model=model_name,
                    existing_summary=existing_summary,
                    history_text=full_history_text,
                )
                summary_record = ChatSummaryRecord(
                    conversation_id=st.session_state.chat_conversation_id,
                    content=summ_res.text,
                    ts=time.time(),
                    meta={
                        "summary_latency_s": summ_res.latency_s,
                        "summary_error": summ_res.error,
                    },
                )
                store.upsert_summary(summary_record)
                st.session_state.chat_summary = summary_record

            st.rerun()
