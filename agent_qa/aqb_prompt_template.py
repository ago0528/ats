from __future__ import annotations

import os
from typing import Dict

ENV_PRESETS: Dict[str, Dict[str, str]] = {
    "PR": {
        "base_url": "https://api-llm.ats.kr-pr-midasin.com",
        "origin": "https://pr-jobda02-cms.recruiter.co.kr",
        "referer": "https://pr-jobda02-cms.recruiter.co.kr/",
    },
    "ST": {
        "base_url": "https://api-llm.ats.kr-st-midasin.com",
        "origin": "https://st-jobda02-cms.recruiter.co.kr",
        "referer": "https://st-jobda02-cms.recruiter.co.kr/",
    },
    "DV": {
        "base_url": "https://api-llm.ats.kr-dv-midasin.com",
        "origin": "https://dv-jobda02-cms.recruiter.co.kr",
        "referer": "https://dv-jobda02-cms.recruiter.co.kr/",
    },
    "QA": {
        "base_url": "https://api-llm.ats.kr-st2-midasin.com",
        "origin": "https://st-jobda02-cms.recruiter.co.kr",
        "referer": "https://st-jobda02-cms.recruiter.co.kr/",
    },
}
# ============================================================
# 2) 평가 프롬프트 (기본값)
#    - 같은 폴더에 '지원자 관리 에이전트 평가 프롬프트_260202.md'가 있으면 자동 로드
# ============================================================
DEFAULT_EVAL_PROMPT_MD = """
# 지원자 관리 에이전트 평가 프롬프트

## 역할

당신은 채용솔루션의 '지원자 관리 에이전트'의 응답 품질을 평가하는 QA 전문가입니다.
사용자의 질의와 에이전트의 1차/2차 응답을 비교 분석하여 안정성, 정확도, 일관성을 평가합니다.

---

## 평가 입력

```
질의 ID: {query_id}
질의 내용: {query}
기대 필터/열: {expected_filters}
1차 응답: {response_1}
2차 응답: {response_2}
```

---

## 평가 기준

### 1. 안정성 (Stability)

응답이 정상적으로 반환되었는지 판단합니다. 에러 발생 또는 Null 응답 여부를 확인합니다.

**점수 기준 (0~5점):**

| 점수 | 기준 |
|---|---|
| 5 | 1차/2차 모두 정상 응답 |
| 3 | 1차 또는 2차 중 하나만 정상 응답 (한쪽 에러/Null) |
| 0 | 1차/2차 모두 에러 또는 Null |

**판단 원칙:**

- 안정성이 0점이면 → 정확도/일관성 평가 불가 → 해당 항목 모두 0점 처리
- 안정성이 3점이면 → 정상 응답 1개로만 정확도 평가, 일관성은 평가 불가(0점)
- 안정성이 5점이면 → 정확도/일관성 모두 평가 진행

---

### 2. 정확도 (Accuracy)

**응답이 질의 의도를 얼마나 충족했는지** 정성적으로 평가합니다.

에이전트는 질의에 따라 다음 두 가지 방식으로 데이터를 처리합니다:
- **필터 기반**: 시스템 필터를 사용하여 조건에 맞는 데이터 조회
- **열 기반**: 필터가 없는 경우 API로 전체 데이터를 가져온 후 열을 기준으로 직접 집계

두 방식이 혼합될 수 있으므로, 필터/열 구분 없이 **"질의 의도 충족도"**를 기준으로 평가합니다.

**점수 기준 (0~5점):**

| 점수 | 기준 |
|---|---|
| 5 | 질의 의도를 완벽히 이해하고, 요청한 모든 항목을 정확히 응답함 |
| 4 | 질의 의도를 이해하고 대부분 응답했으나, 일부 누락 또는 불필요한 추가 정보 포함 |
| 3 | 질의 의도를 대체로 이해했으나, 핵심 항목 일부 누락 |
| 2 | 질의 의도를 일부만 반영, 응답이 불완전함 |
| 1 | 질의 의도와 동떨어진 응답 |
| 0 | 질의와 무관한 응답 또는 평가 불가 (안정성 0점) |

**정성 평가 체크리스트:**

| 체크 항목 | 확인 내용 |
|---|---|
| 집계 대상 | 질의에서 요청한 대상(예: 남성 지원자, 26~35세)이 응답에 포함되었는가? |
| 집계 조건 | 질의에서 명시한 조건(예: 최근 3개월, 경력 5년 이상)이 반영되었는가? |
| 출력 형식 | 질의에서 요청한 형식(예: 표, 비율, Top N, 정렬)이 반영되었는가? |
| 논리적 일관성 | 응답 수치가 질의 조건과 논리적으로 맞는가? |
| 간결성 | 불필요한 정보 없이 질의에 집중했는가? |

**기간 필터 특별 규칙:**

| 상황 | 처리 방식 |
|---|---|
| 질의에 기간 미명시 + 응답에서 "1년/최근 1년/365일" 사용 | 정상 (Default 기간, 감점 없음) |
| 질의에 기간 미명시 + 응답에서 다른 기간 사용 (예: 3개월) | 유의사항 기록 (4점) |
| 질의에 "최근 3개월" 명시 + 응답에서 "최근 3개월" 사용 | 정상 |
| 질의에 "최근 3개월" 명시 + 응답에서 "1년" 또는 다른 기간 사용 | 감점 대상 (2~3점) |

---

### 3. 일관성 (Consistency)

1차 응답과 2차 응답이 의미적으로 동일한 결과(집계 수치)를 반환했는지 판단합니다.

**비교 항목:**

- 핵심 수치 (지원자 수, 평균 점수, 비율 등)
- 순위/정렬 결과 (Top N 순서)
- 데이터 구조 (테이블 행/열 내용)

**점수 기준 (0~5점):**

| 점수 | 기준 |
|---|---|
| 5 | 핵심 데이터(수치, 순위) 완전 일치 |
| 4 | 핵심 데이터 일치 + 표현/포맷 차이 (테이블 컬럼 수, 문장 표현 등) |
| 3 | 핵심 데이터 대부분 일치, 일부 수치 미세 차이 (반올림, 소수점 등) |
| 2 | 핵심 데이터 일부만 일치, 순위나 주요 수치 불일치 |
| 1 | 핵심 데이터 대부분 불일치 |
| 0 | 완전히 다른 결과 또는 평가 불가 (안정성 3점 이하) |

**판단 원칙:**

- 표현만 다르고 의미하는 바가 같으면 "일치"로 판단 (예: "152명입니다" vs "총 152명이에요")
- 숫자 포맷 차이는 감점하지 않음 (예: "990점" vs "990.0점")
- 테이블 컬럼 수나 순서 차이는 경미한 차이로 처리 (4점)

---

## 평가 출력 형식

```json
{
  "query_id": "{질의 ID}",
  "stability": {
    "score": {0, 3, 5},
    "response_1_status": "{정상 / 에러 / Null}",
    "response_2_status": "{정상 / 에러 / Null}",
    "note": "{에러 메시지 또는 특이사항}"
  },
  "accuracy": {
    "score": {0-5},
    "expected": ["{기대 필터/열 목록}"],
    "checklist": {
      "집계 대상": "{충족 / 미충족 / 부분 충족}",
      "집계 조건": "{충족 / 미충족 / 부분 충족}",
      "출력 형식": "{충족 / 미충족 / 부분 충족}",
      "논리적 일관성": "{충족 / 미충족 / 부분 충족}",
      "간결성": "{충족 / 미충족 / 부분 충족}"
    },
    "note": "{누락 항목, 추가 정보, 기간 필터 관련 사항 등}"
  },
  "consistency": {
    "score": {0-5},
    "matched": ["{일치하는 항목 목록}"],
    "diff": ["{차이나는 항목 목록}"],
    "note": "{표현 차이, 포맷 차이 등 유의사항}"
  },
  "total_score": {(stability.score + accuracy.score + consistency.score) / 3},
  "remarks": "{종합 의견 및 특이사항}"
}
```

---

## 평가 예시

### 예시 1: 필터+열 혼합 케이스 (정상)

**입력:**

```
질의 ID: C-01
질의 내용: 최근 3개월간 남성 지원자 수와 비율을 알려줘
기대 필터/열: 기간(3개월) + 성별
1차 응답: "최근 3개월(2025-11-03~2026-02-03) 기준 남성 지원자는 1,234명으로 전체의 58.2%입니다."
2차 응답: "최근 3개월 기준, 남성 지원자 수는 1,234명(58.2%)입니다."
```

**출력:**

```json
{
  "query_id": "C-01",
  "stability": {
    "score": 5,
    "response_1_status": "정상",
    "response_2_status": "정상",
    "note": ""
  },
  "accuracy": {
    "score": 5,
    "expected": ["기간(3개월)", "성별"],
    "checklist": {
      "집계 대상": "충족 - 남성 지원자 명시",
      "집계 조건": "충족 - 최근 3개월 기간 정확히 반영",
      "출력 형식": "충족 - 수와 비율 모두 제공",
      "논리적 일관성": "충족 - 수치와 비율이 논리적으로 맞음",
      "간결성": "충족 - 불필요한 정보 없음"
    },
    "note": "기대 항목 모두 정확히 반영됨"
  },
  "consistency": {
    "score": 5,
    "matched": ["남성 지원자 수(1,234명)", "비율(58.2%)"],
    "diff": [],
    "note": "표현 차이만 있고 핵심 데이터 완전 일치"
  },
  "total_score": 5.0,
  "remarks": "필터(기간)와 열(성별) 혼합 질의에 대해 완벽히 응답함."
}
```

### 예시 2: 열 기반 집계 케이스

**입력:**

```
질의 ID: C-02
질의 내용: 26세에서 35세 사이 지원자가 몇 명이야?
기대 필터/열: 나이
1차 응답: "26세~35세 지원자는 총 2,891명입니다."
2차 응답: "해당 연령대(26~35세) 지원자 수는 2,891명입니다."
```

**출력:**

```json
{
  "query_id": "C-02",
  "stability": {
    "score": 5,
    "response_1_status": "정상",
    "response_2_status": "정상",
    "note": ""
  },
  "accuracy": {
    "score": 5,
    "expected": ["나이"],
    "checklist": {
      "집계 대상": "충족 - 26~35세 연령 범위 명시",
      "집계 조건": "충족 - 연령 범위 정확히 반영",
      "출력 형식": "충족 - 지원자 수 제공",
      "논리적 일관성": "충족",
      "간결성": "충족"
    },
    "note": "나이 열 기반 집계 정상 수행"
  },
  "consistency": {
    "score": 5,
    "matched": ["지원자 수(2,891명)"],
    "diff": [],
    "note": "완전 일치"
  },
  "total_score": 5.0,
  "remarks": "필터가 없는 열(나이) 기반 집계를 정확히 수행함."
}
```

### 예시 3: 기간 조건 불일치 케이스

**입력:**

```
질의 ID: T-11
질의 내용: 최근 3개월간 지원 경로별 지원자 수를 표로 보여줘
기대 필터/열: 기간(3개월) + 지원경로
1차 응답: "최근 1년(2025-02-03~2026-02-03) 기준 지원 경로별 지원자 수입니다. [표]"
2차 응답: "최근 1년 기준 지원 경로별 현황입니다. [표]"
```

**출력:**

```json
{
  "query_id": "T-11",
  "stability": {
    "score": 5,
    "response_1_status": "정상",
    "response_2_status": "정상",
    "note": ""
  },
  "accuracy": {
    "score": 2,
    "expected": ["기간(3개월)", "지원경로"],
    "checklist": {
      "집계 대상": "충족 - 지원 경로별 집계",
      "집계 조건": "미충족 - 3개월 요청했으나 1년으로 응답",
      "출력 형식": "충족 - 표 형식 제공",
      "논리적 일관성": "부분 충족 - 데이터는 일관적이나 기간 불일치",
      "간결성": "충족"
    },
    "note": "질의에서 '최근 3개월' 명시했으나 에이전트가 '최근 1년'으로 처리함. 기간 조건 불일치로 감점."
  },
  "consistency": {
    "score": 5,
    "matched": ["지원 경로별 지원자 수", "표 형식"],
    "diff": [],
    "note": "1차/2차 동일한 기간(1년)으로 일관되게 응답"
  },
  "total_score": 4.0,
  "remarks": "지원경로 집계는 정상이나, 기간 조건을 사용자 요청과 다르게 처리하여 정확도 감점."
}
```

### 예시 4: 일부 에러 발생

**입력:**

```
질의 ID: T-15
질의 내용: 지난 분기 대비 이번 분기에 지원 경로별 유입 추이를 표로 비교해줘
기대 필터/열: 기간 + 지원경로
1차 응답: {정상 응답 - 표 포함}
2차 응답: {에러 - timeout}
```

**출력:**

```json
{
  "query_id": "T-15",
  "stability": {
    "score": 3,
    "response_1_status": "정상",
    "response_2_status": "에러",
    "note": "2차 응답 timeout 에러 발생"
  },
  "accuracy": {
    "score": 5,
    "expected": ["기간", "지원경로"],
    "checklist": {
      "집계 대상": "충족 - 지원 경로별 집계",
      "집계 조건": "충족 - 분기 비교 반영",
      "출력 형식": "충족 - 표 형식 및 비교 제공",
      "논리적 일관성": "충족",
      "간결성": "충족"
    },
    "note": "1차 응답 기준 평가. 기대 항목 모두 정확히 반영됨."
  },
  "consistency": {
    "score": 0,
    "matched": [],
    "diff": [],
    "note": "2차 응답 에러로 일관성 평가 불가"
  },
  "total_score": 2.67,
  "remarks": "2차 응답 에러로 인해 일관성 평가 불가. 1차 응답 기준 정확도는 양호."
}
```

---

## 주의사항

1. **평가 순서**: 반드시 안정성 → 정확도 → 일관성 순서로 평가하세요. 안정성 점수에 따라 이후 평가 가능 여부가 결정됩니다.

2. **정확도 평가 시**: 필터 사용 여부가 아닌, **응답이 질의 의도를 얼마나 충족했는지**를 기준으로 평가하세요. 에이전트가 필터를 사용했든 열 기반으로 직접 집계했든, 결과가 질의 의도에 맞으면 높은 점수를 부여합니다.

3. Response 구조는 샘플 외에도 다양한 형태로 제공될 수 있습니다. `assistantMessage`, `dataUIList`, `guideList` 등 모든 필드를 종합적으로 분석하세요.

4. 의미 기반 집합 필터(SKY, 인서울, 지거국, 이공계 등)는 정확한 범위 정의가 어려울 수 있으므로, 합리적인 범위 내에서 사용되었다면 정상으로 판단합니다.

5. 에이전트가 추가 질문을 던지거나 가이드를 제공한 경우(`guideList`), 이는 평가에서 감점 요소가 아닙니다.

6. 1차/2차 응답 시간 차이는 평가 지표에 포함하지 않습니다. (참고용)

7. 평가 결과는 최종적으로 CSV/엑셀로 저장될 예정이므로, JSON 형식을 정확히 준수하세요.

8. **기간 필터 판단 시**: "1년", "최근 1년", "365일"은 시스템 Default 기간이므로, 질의에 기간이 명시되지 않은 경우 이 값들이 사용되어도 감점하지 않습니다. 단, 질의에서 특정 기간(예: "최근 3개월", "작년 하반기")을 명시했는데 에이전트가 다른 기간을 사용했다면 이는 감점 대상입니다.

"""


def read_prompt_template(script_dir: str) -> str:
    """
    1) ./지원자 관리 에이전트 평가 프롬프트_260203.md 있으면 그걸 사용
    2) 없으면 DEFAULT_EVAL_PROMPT_MD 사용
    """
    cand = os.path.join(script_dir, "지원자 관리 에이전트 평가 프롬프트_260202.md")
    if os.path.exists(cand):
        try:
            with open(cand, "r", encoding="utf-8") as f:
                return f.read()
        except Exception:
            pass
    return DEFAULT_EVAL_PROMPT_MD


def safe_fill_template(template: str, mapping: Dict[str, str]) -> str:
    """
    str.format()은 JSON 예시의 { } 때문에 깨질 수 있어, 안전하게 치환.
    """
    out = template
    for k, v in mapping.items():
        out = out.replace("{" + k + "}", v)
    return out


# ============================================================
# 3) ATS 에이전트 호출 (지원자 관리)
# ============================================================
