"""
ì±„ìš© ì—ì´ì „íŠ¸ ê²€ì¦ ë°±ì˜¤í”¼ìŠ¤ / ì—…ë°ì´íŠ¸ì¼ì: 260212
- ëª©ì :
  1) CSV(ì§ˆì˜/ê¸°ëŒ€í•„í„°)ë¥¼ ì—…ë¡œë“œí•´ì„œ ì§€ì›ì ê´€ë¦¬ ì—ì´ì „íŠ¸ë¥¼ 1ì°¨/2ì°¨(ë™ì¼ ì„¸ì…˜)ë¡œ í˜¸ì¶œ
  2) "ì§€ì›ì ê´€ë¦¬ ì—ì´ì „íŠ¸ í‰ê°€ í”„ë¡¬í”„íŠ¸" í”„ë ˆì„ì›Œí¬ì— ë§ì¶° ChatGPT(OpenAI API)ë¡œ ìë™ í‰ê°€(JSON)
  3) ê²°ê³¼ë¥¼ í‘œë¡œ í™•ì¸í•˜ê³  Excelë¡œ ë‹¤ìš´ë¡œë“œ
  4) í•„ìš” ì‹œ 'URL Agent(ì´ë™/ë²„íŠ¼URL)' ë²Œí¬ í…ŒìŠ¤íŠ¸ë„ ê°™ì€ í™”ë©´ì—ì„œ ì‹¤í–‰
  5) AQB v1.2.0 ì ìˆ˜ ê³„ì‚°(ë³„ë„ íƒ­/ì‹œíŠ¸)

ì‹¤í–‰:
streamlit run aqb_v1.2.0.py

.env (ì´ íŒŒì¼ê³¼ ê°™ì€ í´ë” ê¶Œì¥):
  # ATS(ì±„ìš©ì†”ë£¨ì…˜) í† í°
  ATS_BEARER_TOKEN=...
  ATS_CMS_TOKEN=...
  ATS_MRS_SESSION=...

  # OpenAI (ChatGPT í‰ê°€)
  OPENAI_API_KEY=...
  OPENAI_MODEL=gpt-5.2

ì£¼ì˜:
- í† í°/í‚¤ëŠ” ì ˆëŒ€ ê¹ƒì— ì»¤ë°‹í•˜ì§€ ë§ˆì„¸ìš”.
"""

from __future__ import annotations

import asyncio
import json
import os
import sys
import time
from datetime import datetime
from typing import Any, Dict, Optional

import aiohttp
import pandas as pd
import streamlit as st

# ìƒìœ„ í´ë”(ax)ì˜ ëª¨ë“ˆì„ importí•˜ê¸° ìœ„í•´ ê²½ë¡œ ì¶”ê°€
_AX_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if _AX_DIR not in sys.path:
    sys.path.insert(0, _AX_DIR)

from curl_parsing import parse_curl_headers
from prompt_api import AxPromptApiClient, WORKER_DESCRIPTIONS, WORKER_TYPES, safe_len

from aqb_agent_client import ApplicantAgentClient
from aqb_bulk_runner import normalize_columns, run_applicant_calls_async, run_openai_judge_async
from aqb_common_utils import (
    build_applicant_csv_template,
    build_generic_csv_template,
    build_url_csv_template,
    load_dotenv,
    make_arrow_safe,
    run_logic_check,
)
from aqb_openai_judge import openai_judge_with_retry
from aqb_prompt_template import ENV_PRESETS, read_prompt_template
from aqb_runtime_utils import dataframe_to_excel_bytes, dataframes_to_excel_bytes, run_async
from aqb_url_tester import UrlAgentTester, run_url_tests_async
from aqb_aqb_scoring import (
    AQB_RULES_SUMMARY_MD,
    AQB_RUBRIC_MD,
    build_aqb_agent_summary,
    build_aqb_precheck_report,
    build_aqb_round_summary,
    run_aqb_scoring_async,
)

def main():
    st.set_page_config(page_title="ì±„ìš© ì—ì´ì „íŠ¸ ê²€ì¦ ë°±ì˜¤í”¼ìŠ¤", page_icon="ğŸ§ª", layout="wide")

    script_dir = os.path.dirname(os.path.abspath(__file__))

    # .env ìë™ ë¡œë“œ
    loaded_env = load_dotenv(os.path.join(script_dir, ".env"))

    st.title("ğŸ§ª ì±„ìš© ì—ì´ì „íŠ¸ ê²€ì¦ ë°±ì˜¤í”¼ìŠ¤")

    with st.sidebar:
        st.header("ì„¤ì •")
        st.caption("í† í°/í‚¤ëŠ” .env ë˜ëŠ” ì•„ë˜ ì…ë ¥ìœ¼ë¡œ ì£¼ì…í•˜ì„¸ìš”. (ì»¤ë°‹ ê¸ˆì§€)")

        # ENV ì„ íƒ
        env = st.selectbox("í™˜ê²½ (DV/QA/ST/PR)", ["PR", "ST", "QA", "DV"], index=0)
        preset = ENV_PRESETS.get(env, {})

        base_url = st.text_input("ATS base_url", value=preset.get("base_url", ""), placeholder="https://api-llm....")
        origin = st.text_input("origin", value=preset.get("origin", ""), placeholder="https://...cms...")
        referer = st.text_input("referer", value=preset.get("referer", ""), placeholder="https://.../")

        st.divider()
        st.subheader("ATS í† í°")

        # cURL ë¶™ì—¬ë„£ê¸° ê¸°ëŠ¥
        with st.expander("ğŸ“‹ cURLë¡œ í† í° ìë™ ì…ë ¥", expanded=False):
            curl_text = st.text_area(
                "cURL ëª…ë ¹ì–´ ë¶™ì—¬ë„£ê¸°",
                placeholder="curl 'https://...' -H 'authorization: Bearer ...' -H 'cms-access-token: ...' ...",
                height=100,
                key="curl_input"
            )
            if st.button("ğŸ”‘ ì¸ì¦ ì •ë³´ íŒŒì‹±", key="parse_curl"):
                if curl_text.strip():
                    parsed = parse_curl_headers(curl_text)
                    # Bearer ì ‘ë‘ì‚¬ ì œê±°
                    auth_val = parsed.get("authorization") or ""
                    if auth_val.lower().startswith("bearer "):
                        auth_val = auth_val[7:]
                    st.session_state["parsed_bearer"] = auth_val
                    st.session_state["parsed_cms"] = parsed.get("cms-access-token") or ""
                    st.session_state["parsed_mrs"] = parsed.get("mrs-session") or ""

                    # íŒŒì‹± ê²°ê³¼ í‘œì‹œ
                    if auth_val or parsed.get("cms-access-token") or parsed.get("mrs-session"):
                        st.success("âœ… í† í° íŒŒì‹± ì™„ë£Œ! ì•„ë˜ ì…ë ¥ í•„ë“œì— ìë™ ì ìš©ë©ë‹ˆë‹¤.")
                    else:
                        st.warning("âš ï¸ cURLì—ì„œ í† í°ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                else:
                    st.warning("cURL ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

        # íŒŒì‹±ëœ í† í°ì´ ìˆìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©
        default_bearer = st.session_state.get("parsed_bearer") or os.getenv("ATS_BEARER_TOKEN", "")
        default_cms = st.session_state.get("parsed_cms") or os.getenv("ATS_CMS_TOKEN", "")
        default_mrs = st.session_state.get("parsed_mrs") or os.getenv("ATS_MRS_SESSION", "")

        bearer = st.text_input("ATS_BEARER_TOKEN", value=default_bearer, type="password")
        cms = st.text_input("ATS_CMS_TOKEN", value=default_cms, type="password")
        mrs = st.text_input("ATS_MRS_SESSION", value=default_mrs, type="password")

        # ì„¸ì…˜ í™•ì¸ ë²„íŠ¼
        if st.button("ğŸ” ì„¸ì…˜ í™•ì¸", key="check_session"):
            if base_url and bearer and cms and mrs:
                async def check_session():
                    connector = aiohttp.TCPConnector(ssl=False)
                    timeout = aiohttp.ClientTimeout(total=30)
                    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
                        url = f"{base_url.rstrip('/')}/api/v2/ai/orchestrator/query"
                        headers = {
                            "authorization": f"Bearer {bearer}",
                            "cms-access-token": cms,
                            "mrs-session": mrs,
                            "origin": origin,
                            "referer": referer,
                            "accept": "application/json, text/plain, */*",
                            "content-type": "application/json",
                        }
                        payload = {"conversationId": None, "userMessage": "í…ŒìŠ¤íŠ¸"}
                        try:
                            async with session.post(url, headers=headers, json=payload) as resp:
                                return resp.status == 200, resp.status
                        except Exception as e:
                            return False, str(e)

                ok, status = run_async(check_session())
                if ok:
                    st.success(f"âœ… ì„¸ì…˜ ìœ íš¨ (HTTP 200)")
                else:
                    st.error(f"âŒ ì„¸ì…˜ ë¬´íš¨ ë˜ëŠ” ì˜¤ë¥˜: {status}")

        st.divider()
        st.subheader("OpenAI (ChatGPT í‰ê°€)")

        # ì£¼ìš” ì„¤ì • (í•­ìƒ í‘œì‹œ)
        judge_parallel = st.slider("LLM ë³‘ë ¬ìˆ˜", min_value=1, max_value=10, value=3, step=1)
        max_chars = st.slider("ì‘ë‹µ ìµœëŒ€ ê¸¸ì´(í‰ê°€ ì…ë ¥)", min_value=2000, max_value=30000, value=15000, step=1000)

        # ê³ ê¸‰ ì„¤ì • (ì ‘ê¸°)
        with st.expander("âš™ï¸ ê³ ê¸‰ ì„¤ì •", expanded=False):
            openai_key = st.text_input("OPENAI_API_KEY", value=os.getenv("OPENAI_API_KEY", ""), type="password")
            openai_model = st.text_input("OPENAI_MODEL", value=os.getenv("OPENAI_MODEL", "gpt-5.2"))

            # ë¹„ìš© ê³„ì‚°ìš©(ì„ íƒ): 1M í† í°ë‹¹ USD
            st.caption("ë¹„ìš© ê³„ì‚°ìš© (ì„ íƒì‚¬í•­)")
            try:
                default_in = float(os.getenv("OPENAI_PRICE_INPUT_PER_1M", "0") or 0)
            except Exception:
                default_in = 0.0
            try:
                default_out = float(os.getenv("OPENAI_PRICE_OUTPUT_PER_1M", "0") or 0)
            except Exception:
                default_out = 0.0
            try:
                default_cached = float(os.getenv("OPENAI_PRICE_CACHED_INPUT_PER_1M", "0") or 0)
            except Exception:
                default_cached = 0.0

            price_input_per_1m = st.number_input("Input $/1M tokens", min_value=0.0, value=default_in, step=0.1, format="%.4f")
            price_output_per_1m = st.number_input("Output $/1M tokens", min_value=0.0, value=default_out, step=0.1, format="%.4f")
            price_cached_input_per_1m = st.number_input("Cached input $/1M tokens", min_value=0.0, value=default_cached, step=0.1, format="%.4f")

        st.divider()
        st.subheader("ì‹¤í–‰ ì˜µì…˜")
        agent_parallel = st.slider("ATS í˜¸ì¶œ ë³‘ë ¬ìˆ˜", min_value=1, max_value=10, value=3, step=1)
        n_calls = st.slider(
            "ì±„íŒ… í˜¸ì¶œ íšŸìˆ˜",
            min_value=1, max_value=4, value=1, step=1,
            help="ë™ì¼ conversationIdì—ì„œ ê°™ì€ ì§ˆë¬¸ì„ Në²ˆ ë°˜ë³µ (ì¼ê´€ì„± í…ŒìŠ¤íŠ¸ìš©). 1ì´ë©´ ì¼ê´€ì„± í‰ê°€ ì œì™¸."
        )
        independent_sessions = st.checkbox(
            "ì¼ê´€ì„±ìš© ë…ë¦½ ì„¸ì…˜ í˜¸ì¶œ",
            value=True,
            help="ONì´ë©´ níšŒ í˜¸ì¶œì„ ê°ê° ë…ë¦½ ì±„íŒ…ë°©ì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤. (ì¼ê´€ì„± ì •ì‹ ê¸°ì¤€ ê¶Œì¥)",
        )
        only_missing = st.checkbox("ì´ë¯¸ ì±„ì›Œì§„ rowëŠ” ìŠ¤í‚µ", value=True)
        limit_rows = st.number_input("ìƒìœ„ Nê°œë§Œ ì‹¤í–‰ (0=ì „ì²´)", min_value=0, value=0, step=1)
        limit_rows = None if int(limit_rows) == 0 else int(limit_rows)

        st.caption("âœ… .env ë¡œë“œë¨" if loaded_env else "âš ï¸ .env ë¯¸ë¡œë“œ(ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŒ)")

    tab_generic, tab_applicant, tab_url, tab_quality, tab_prompt = st.tabs(
        ["ë²”ìš© í…ŒìŠ¤íŠ¸", "ì§€ì›ì ì—ì´ì „íŠ¸ ê²€ì¦", "ì´ë™ ì—ì´ì „íŠ¸ ê²€ì¦", "í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°", "í”„ë¡¬í”„íŠ¸ ê´€ë¦¬"]
    )

    # --------------------------------------------
    # Tab 2: ì§€ì›ì ì—ì´ì „íŠ¸ ê²€ì¦
    # --------------------------------------------
    with tab_applicant:
        st.subheader("1) CSV ì—…ë¡œë“œ")

        # ì—…ë¡œë“œìš© CSV í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ
        st.download_button(
            "â¬‡ï¸ ì—…ë¡œë“œìš© CSV ì–‘ì‹ ë‹¤ìš´ë¡œë“œ",
            data=build_applicant_csv_template(),
            file_name="ì§€ì›ì_ê´€ë¦¬_ì§ˆì˜_í…œí”Œë¦¿.csv",
            mime="text/csv",
        )

        uploaded = st.file_uploader("ì§€ì›ì ê´€ë¦¬ ì§ˆì˜ CSV", type=["csv"])

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ + í¸ì§‘
        st.subheader("2) í‰ê°€ í”„ë¡¬í”„íŠ¸")
        prompt_default = read_prompt_template(script_dir)
        prompt_text = st.text_area("í‰ê°€ í”„ë¡¬í”„íŠ¸(ìˆ˜ì • ê°€ëŠ¥)", value=prompt_default, height=320)

        if uploaded is None:
            st.info("CSVë¥¼ ì—…ë¡œë“œí•˜ë©´ ì‹¤í–‰í•  ìˆ˜ ìˆì–´ìš”.")
        else:
            try:
                df_in = pd.read_csv(uploaded, encoding="utf-8")
            except Exception:
                df_in = pd.read_csv(uploaded, encoding="utf-8-sig")
            df_in = normalize_columns(df_in)

            st.write("ë¯¸ë¦¬ë³´ê¸°", df_in.head(10))

            # Context ë° targetAssistant ì„¤ì •
            st.subheader("3) API ì„¤ì • (ì„ íƒ)")
            col_ctx, col_target = st.columns(2)

            with col_ctx:
                use_context = st.checkbox("Context ì‚¬ìš©", value=False, help="API í˜¸ì¶œ ì‹œ context ê°ì²´ë¥¼ í•¨ê»˜ ì „ì†¡")
                context_obj: Optional[Dict[str, Any]] = None
                if use_context:
                    context_input = st.text_area(
                        "Context (JSON í˜•ì‹)",
                        value='{"recruitPlanId": 123}',
                        height=80,
                        help='ì˜ˆ: {"recruitPlanId": 123, "ì±„ìš©ëª…": "2026ë…„ ê³µì±„"}'
                    )
                    try:
                        context_obj = json.loads(context_input)
                        st.success("âœ… JSON íŒŒì‹± ì„±ê³µ")
                    except json.JSONDecodeError as e:
                        st.error(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                        context_obj = None

            with col_target:
                use_target_assistant = st.checkbox("targetAssistant ì§€ì •", value=False, help="íŠ¹ì • ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ì§€ì •í•˜ì—¬ í˜¸ì¶œ")
                target_assistant: Optional[str] = None
                if use_target_assistant:
                    target_assistant = st.text_input(
                        "targetAssistant",
                        value="RECRUIT_PLAN_ASSISTANT",
                        help='ì˜ˆ: RECRUIT_PLAN_ASSISTANT, RECRUIT_PLAN_CREATE_ASSISTANT'
                    )

            # ì‹¤í–‰ ë²„íŠ¼
            st.subheader("4) ì‹¤í–‰")
            colA, colB, colC = st.columns(3)
            run_calls = colA.button("â‘  ATS í˜¸ì¶œë§Œ ì‹¤í–‰", key="tab2_run_calls")
            run_judge = colB.button("â‘¡ LLM í‰ê°€ë§Œ ì‹¤í–‰", key="tab2_run_judge")
            run_all = colC.button("â‘¢ ì „ì²´ ì‹¤í–‰(í˜¸ì¶œ+í‰ê°€)", key="tab2_run_all")

            # ì§„í–‰ë¥  í‘œì‹œ ì˜ì—­ (ê°œì„ : ì—…ë°ì´íŠ¸ í˜•íƒœ)
            progress = st.progress(0)
            progress_placeholder = st.empty()

            # ì„ì‹œ ì €ì¥ ê²½ë¡œ
            temp_save_path = os.path.join(script_dir, f"_autosave_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")

            def auto_save_callback(df_partial: pd.DataFrame):
                try:
                    df_partial.to_csv(temp_save_path, index=False, encoding="utf-8-sig")
                    st.toast(f"ğŸ’¾ ìë™ ì €ì¥ ì™„ë£Œ ({temp_save_path})")
                except Exception as e:
                    st.toast(f"âš ï¸ ìë™ ì €ì¥ ì‹¤íŒ¨: {e}")

            def progress_cb(done: int, total: int, msg: str, elapsed: float = 0.0, completed: int = 0):
                if total > 0:
                    progress.progress(min(1.0, done / total))
                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (í•˜ë‚˜ì˜ placeholderì—ì„œ ê°±ì‹ )
                if done > 0 and elapsed > 0:
                    avg_time = elapsed / done
                    remaining = (total - done) * avg_time
                    progress_placeholder.markdown(
                        f"**ì§„í–‰** {done}/{total} | **ì´ ê²½ê³¼ ì‹œê°„** {elapsed:.1f}ì´ˆ (ì•½ {remaining:.0f}ì´ˆ ë‚¨ìŒ)"
                    )
                else:
                    progress_placeholder.markdown(f"**ì§„í–‰** {done}/{total} | **ì´ ê²½ê³¼ ì‹œê°„** {elapsed:.1f}ì´ˆ")

            # ìƒíƒœ dfëŠ” session_stateì— ë³´ê´€
            if "applicant_df" not in st.session_state:
                st.session_state["applicant_df"] = df_in

            # ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ session_stateë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‹¤í–‰
            if run_calls or run_all:
                if not (base_url and origin and referer and bearer and cms and mrs):
                    st.error("ATS ì„¤ì •(base_url/origin/referer)ê³¼ í† í° 3ì¢…ì„ ì…ë ¥í•˜ì„¸ìš”.")
                else:
                    client = ApplicantAgentClient(
                        base_url=base_url,
                        bearer_token=bearer,
                        cms_token=cms,
                        mrs_session=mrs,
                        origin=origin,
                        referer=referer,
                        max_parallel=agent_parallel,
                    )
                    st.session_state["applicant_df"] = run_async(
                        run_applicant_calls_async(
                            st.session_state["applicant_df"],
                            client,
                            progress_cb=progress_cb,
                            only_missing=only_missing,
                            limit_rows=limit_rows,
                            n_calls=n_calls,
                            context=context_obj,
                            target_assistant=target_assistant,
                            independent_sessions=independent_sessions,
                            auto_save_callback=auto_save_callback,
                        )
                    )
                    st.success("ATS í˜¸ì¶œ ì™„ë£Œ")

            if run_judge or run_all:
                if not openai_key:
                    st.error("OPENAI_API_KEYë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
                else:
                    df_result, eval_count = run_async(
                        run_openai_judge_async(
                            st.session_state["applicant_df"],
                            prompt_template=prompt_text,
                            api_key=openai_key,
                            model=openai_model,
                            progress_cb=progress_cb,
                            only_missing=only_missing,
                            limit_rows=limit_rows,
                            max_chars_per_response=max_chars,
                            max_parallel=judge_parallel,
                            price_input_per_1m=price_input_per_1m,
                            price_output_per_1m=price_output_per_1m,
                            price_cached_input_per_1m=price_cached_input_per_1m,
                        )
                    )
                    st.session_state["applicant_df"] = df_result
                    if eval_count == 0:
                        st.warning("LLM í‰ê°€ ëŒ€ìƒì´ ì—†ìŠµë‹ˆë‹¤. (1ì°¨/2ì°¨ raw ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ì´ë¯¸ í‰ê°€ ì™„ë£Œë¨)")
                    else:
                        st.success(f"LLM í‰ê°€ ì™„ë£Œ ({eval_count}ê±´)")

            df_out = st.session_state["applicant_df"]

            st.subheader("5) ê²°ê³¼ ìš”ì•½")
            # ê¸°ë³¸ ìš”ì•½
            total_rows = len(df_out)
            err_rows = df_out["íŠ¹ì´ì‚¬í•­"].astype(str).str.contains("fail|timeout|HTTP|LLM í‰ê°€ ì‹¤íŒ¨", case=False, na=False).sum() if "íŠ¹ì´ì‚¬í•­" in df_out.columns else 0

            c1, c2, c3, c4 = st.columns(4)
            c1.metric("ì´ Row", total_rows)
            c2.metric("ì—ëŸ¬/íŠ¹ì´", int(err_rows))

            if "ì´ì " in df_out.columns:
                try:
                    avg_total = float(pd.to_numeric(df_out["ì´ì "], errors="coerce").dropna().mean())
                except Exception:
                    avg_total = 0.0
                c3.metric("í‰ê·  ì´ì ", f"{avg_total:.1f}")
            else:
                c3.metric("í‰ê·  ì´ì ", "-")

            if "LLM ë¹„ìš©(USD)" in df_out.columns:
                try:
                    total_cost = float(pd.to_numeric(df_out["LLM ë¹„ìš©(USD)"], errors="coerce").fillna(0).sum())
                except Exception:
                    total_cost = 0.0
                c4.metric("LLM ë¹„ìš©(USD)", f"${total_cost:,.4f}")
            else:
                c4.metric("LLM ë¹„ìš©(USD)", "-")

            st.subheader("6) ê²°ê³¼ í…Œì´ë¸”")
            st.dataframe(make_arrow_safe(df_out), use_container_width=True, height=420)

            st.subheader("7) ë‹¤ìš´ë¡œë“œ")
            xlsx_bytes = dataframe_to_excel_bytes(df_out, sheet_name="applicant_results")
            st.download_button(
                "ğŸ“¥ ê²°ê³¼ Excel ë‹¤ìš´ë¡œë“œ",
                data=xlsx_bytes,
                file_name=f"applicant_agent_results_{env}_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )

    # --------------------------------------------
    # Tab í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
    # --------------------------------------------
    with tab_quality:
        st.subheader("í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°")
        st.caption("ì •í™•ì„±(Accuracy)ê³¼ ì‚¬ìš©ì„±(Usability)ì„ ìš°ì„ ìœ¼ë¡œ, ì‹¤í–‰ ì „ í”„ë¦¬ì²´í¬ í›„ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.")

        with st.expander("ì ìˆ˜í™” ê¸°ì¤€(ë£¨ë¸Œë¦­) ë³´ê¸°", expanded=False):
            st.markdown(AQB_RUBRIC_MD)
        with st.expander("í‰ê°€ ê·œì¹™ ìš”ì•½ ë³´ê¸°", expanded=False):
            st.markdown(AQB_RULES_SUMMARY_MD)

        source_candidates = []
        if "generic_df" in st.session_state:
            source_candidates.append(("ë²”ìš© í…ŒìŠ¤íŠ¸ ê²°ê³¼", "generic_df", "generic_results"))
        if "applicant_df" in st.session_state:
            source_candidates.append(("ì§€ì›ì ì—ì´ì „íŠ¸ ê²€ì¦ ê²°ê³¼", "applicant_df", "applicant_results"))
        if "url_df" in st.session_state:
            source_candidates.append(("ì´ë™ ì—ì´ì „íŠ¸ ê²€ì¦ ê²°ê³¼", "url_df", "url_results"))

        if not source_candidates:
            st.info("ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ì†ŒìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í…ŒìŠ¤íŠ¸ íƒ­ì—ì„œ ê²°ê³¼ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        else:
            source_label_to_meta = {label: (key, sheet_name) for label, key, sheet_name in source_candidates}
            source_labels = list(source_label_to_meta.keys())
            default_idx = 0
            for i, lbl in enumerate(source_labels):
                if "ë²”ìš© í…ŒìŠ¤íŠ¸ ê²°ê³¼" in lbl:
                    default_idx = i
                    break

            selected_source_label = st.selectbox(
                "ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ",
                source_labels,
                index=default_idx,
                help="ì ìˆ˜ ê³„ì‚°ì— ì‚¬ìš©í•  ê²°ê³¼ ë°ì´í„°ì…‹ì„ ì„ íƒí•˜ì„¸ìš”.",
            )
            source_key, source_sheet_name = source_label_to_meta[selected_source_label]
            source_df = st.session_state[source_key].copy()
            st.caption(f"ì„ íƒ ì†ŒìŠ¤: `{selected_source_label}` (`{source_key}`)")
            st.write("ì…ë ¥ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", source_df.head(10))

            mode = st.radio("ì„¤ì • ëª¨ë“œ", ["ê°„í¸ ëª¨ë“œ (ì¶”ì²œ)", "ê³ ê¸‰ ëª¨ë“œ"], horizontal=True)
            is_advanced = mode == "ê³ ê¸‰ ëª¨ë“œ"

            tolerance_pct = 1.0
            consistency_min_runs = 3
            allow_two_run_proxy = True
            consistency_under_min_policy = "two_run_proxy"
            use_semantic_llm = True
            use_consistency_llm = True
            allow_force_run = False

            st.subheader("ê³„ì‚° ì˜µì…˜")
            if is_advanced:
                opt1, opt2, opt3 = st.columns(3)
                with opt1:
                    tolerance_pct = st.number_input(
                        "ìˆ˜ì¹˜ í—ˆìš© ì˜¤ì°¨(%)",
                        min_value=0.0,
                        max_value=20.0,
                        value=1.0,
                        step=0.1,
                        format="%.1f",
                        help="ì •í™•ì„±/ì¼ê´€ì„± ìˆ˜ì¹˜ ë¹„êµ í—ˆìš© ì˜¤ì°¨ì…ë‹ˆë‹¤.",
                    )
                with opt2:
                    consistency_min_runs = st.number_input(
                        "ì¼ê´€ì„± ìµœì†Œ ì‘ë‹µ ìˆ˜",
                        min_value=2,
                        max_value=4,
                        value=3,
                        step=1,
                        help="ìš”êµ¬ì‚¬í•­ ê¶Œì¥ê°’ì€ 3íšŒì…ë‹ˆë‹¤.",
                    )
                with opt3:
                    allow_two_run_proxy = st.checkbox(
                        "ì¼ê´€ì„± ë¯¸ë‹¬ ì‹œ ì„ì‹œ 2íšŒ í‰ê°€ í—ˆìš©",
                        value=True,
                        help="ON: 3íšŒ ë¯¸ë‹¬ ì‹œ 2íšŒ ê¸°ì¤€ ì„ì‹œ í‰ê°€ / OFF: 0ì ",
                    )
                consistency_under_min_policy = "two_run_proxy" if allow_two_run_proxy else "zero"

                llm_col1, llm_col2, llm_col3 = st.columns(3)
                with llm_col1:
                    use_semantic_llm = st.checkbox("ì˜ë„ ì¶©ì¡± LLM í‰ê°€", value=True)
                with llm_col2:
                    use_consistency_llm = st.checkbox("ì¼ê´€ì„± LLM í‰ê°€", value=True)
                with llm_col3:
                    allow_force_run = st.checkbox(
                        "í”„ë¦¬ì²´í¬ ì°¨ë‹¨ ê²½ê³  ë¬´ì‹œí•˜ê³  ì‹¤í–‰",
                        value=False,
                        help="ì°¨ë‹¨ FAILì´ ìˆì–´ë„ ê°•ì œë¡œ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.",
                    )
            else:
                use_llm_boost = st.checkbox(
                    "ì˜ë„/ì¼ê´€ì„± LLM ë³´ê°• í‰ê°€ ì‚¬ìš©",
                    value=True,
                    help="OFFë©´ í•´ë‹¹ ì§€í‘œë¥¼ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œë§Œ ê³„ì‚°í•©ë‹ˆë‹¤.",
                )
                use_semantic_llm = use_llm_boost
                use_consistency_llm = use_llm_boost
                allow_two_run_proxy = st.checkbox(
                    "ì¼ê´€ì„± ë¯¸ë‹¬ ì‹œ ì„ì‹œ 2íšŒ í‰ê°€ í—ˆìš©",
                    value=True,
                    help="ê¸°ë³¸ ON ê¶Œì¥",
                )
                consistency_under_min_policy = "two_run_proxy" if allow_two_run_proxy else "zero"
                st.info(
                    "ê°„í¸ ëª¨ë“œ ê¸°ë³¸ê°’: í—ˆìš©ì˜¤ì°¨ Â±1.0%, ì¼ê´€ì„± ìµœì†Œ 3íšŒ, "
                    "TTFTëŠ” PASS/FAILë§Œ í‘œê¸°(ì¢…í•©ì ìˆ˜ ë¯¸ë°˜ì˜)."
                )

            precheck_summary, precheck_df = build_aqb_precheck_report(
                source_df,
                consistency_min_runs=int(consistency_min_runs),
            )

            st.subheader("ì‹¤í–‰ ì „ ì í•©ì„± ì§„ë‹¨ (í”„ë¦¬ì²´í¬)")
            pc1, pc2, pc3, pc4 = st.columns(4)
            pc1.metric("ë¬¸í•­ ìˆ˜", precheck_summary.get("total_rows", 0))
            pc2.metric("ì‘ë‹µ ì»¤ë²„ë¦¬ì§€", f"{precheck_summary.get('response_coverage_pct', 0.0):.2f}%")
            pc3.metric("ì¼ê´€ì„± ì¤€ë¹„ë„", f"{precheck_summary.get('consistency_ready_pct', 0.0):.2f}%")
            pc4.metric("WARN / FAIL", f"{precheck_summary.get('warn_count', 0)} / {precheck_summary.get('fail_count', 0)}")

            if precheck_summary.get("hard_fail"):
                st.error("ì°¨ë‹¨ FAILì´ ìˆìŠµë‹ˆë‹¤. ë°ì´í„°/ì»¬ëŸ¼ì„ ë³´ì™„í•˜ê±°ë‚˜ ê³ ê¸‰ ëª¨ë“œì—ì„œ ê°•í–‰ ì‹¤í–‰ì„ ì„ íƒí•˜ì„¸ìš”.")
            elif precheck_summary.get("warn_count", 0) > 0:
                st.warning("WARN í•­ëª©ì´ ìˆìŠµë‹ˆë‹¤. ì ìˆ˜ ì •í™•ë„ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìœ¼ë‹ˆ ìƒì„¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            else:
                st.success("í”„ë¦¬ì²´í¬ í†µê³¼: í˜„ì¬ ì„¤ì •ìœ¼ë¡œ ì ìˆ˜ ê³„ì‚° ì í•©ë„ê°€ ë†’ìŠµë‹ˆë‹¤.")
            st.dataframe(make_arrow_safe(precheck_df), use_container_width=True, height=240)

            run_aqb_score = st.button("í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì‹¤í–‰", key="run_quality_score")
            if run_aqb_score:
                if precheck_summary.get("hard_fail") and not allow_force_run:
                    st.error("ì°¨ë‹¨ FAILì´ ìˆì–´ ì‹¤í–‰ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤. (ê³ ê¸‰ ëª¨ë“œì—ì„œ ê°•í–‰ ì‹¤í–‰ ê°€ëŠ¥)")
                elif (use_semantic_llm or use_consistency_llm) and not openai_key:
                    st.error("OPENAI_API_KEYë¥¼ ì…ë ¥í•´ì•¼ LLM í‰ê°€ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                else:
                    with st.spinner("í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì¤‘..."):
                        score_df = run_async(
                            run_aqb_scoring_async(
                                source_df,
                                api_key=openai_key if (use_semantic_llm or use_consistency_llm) else "",
                                model=openai_model,
                                max_parallel=judge_parallel,
                                tolerance_pct=float(tolerance_pct),
                                use_semantic_llm=bool(use_semantic_llm),
                                use_consistency_llm=bool(use_consistency_llm),
                                consistency_min_runs=int(consistency_min_runs),
                                consistency_under_min_policy=consistency_under_min_policy,
                            )
                        )
                    round_df = build_aqb_round_summary(score_df)
                    agent_df = build_aqb_agent_summary(score_df)

                    if "aqb_score_store" not in st.session_state:
                        st.session_state["aqb_score_store"] = {}
                    st.session_state["aqb_score_store"][source_key] = {
                        "score_df": score_df,
                        "round_df": round_df,
                        "agent_df": agent_df,
                        "precheck_df": precheck_df,
                    }
                    st.success(f"í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì™„ë£Œ ({len(score_df)}ê±´)")

            score_store = st.session_state.get("aqb_score_store", {})
            if source_key in score_store:
                stored = score_store[source_key]
                df_score = stored.get("score_df", pd.DataFrame()).copy()
                df_round = stored.get("round_df", pd.DataFrame()).copy()
                df_agent = stored.get("agent_df", pd.DataFrame()).copy()
                df_precheck = stored.get("precheck_df", pd.DataFrame()).copy()

                st.subheader("ê²°ê³¼ ìš”ì•½")
                total_rows = len(df_score)
                manual_cnt = (
                    int(df_score["flag_manual_review"].astype(bool).sum())
                    if "flag_manual_review" in df_score.columns
                    else 0
                )

                avg_total = 0.0
                if not df_agent.empty and "weighted_total_avg" in df_agent.columns:
                    try:
                        avg_total = float(pd.to_numeric(df_agent["weighted_total_avg"], errors="coerce").dropna().mean())
                    except Exception:
                        avg_total = 0.0

                avg_accuracy = 0.0
                if not df_agent.empty and "accuracy_avg" in df_agent.columns:
                    try:
                        avg_accuracy = float(pd.to_numeric(df_agent["accuracy_avg"], errors="coerce").dropna().mean())
                    except Exception:
                        avg_accuracy = 0.0

                avg_stability = 0.0
                if not df_agent.empty and "stability_avg" in df_agent.columns:
                    try:
                        avg_stability = float(pd.to_numeric(df_agent["stability_avg"], errors="coerce").dropna().mean())
                    except Exception:
                        avg_stability = 0.0

                sm1, sm2, sm3, sm4 = st.columns(4)
                sm1.metric("ë¬¸í•­ ìˆ˜", total_rows)
                sm2.metric("ì—ì´ì „íŠ¸ í‰ê·  ì¢…í•©ì ìˆ˜", f"{avg_total:.2f}")
                sm3.metric("í‰ê·  ì •í™•ì„± / ì•ˆì •ì„±", f"{avg_accuracy:.2f} / {avg_stability:.2f}")
                sm4.metric("ìˆ˜ê¸° í™•ì¸ í•„ìš”", manual_cnt)

                st.subheader("ë¬¸í•­ë³„ ì ìˆ˜")
                st.caption("`*_calc_method` ì»¬ëŸ¼ìœ¼ë¡œ ê° ì§€í‘œ ì ìˆ˜ ì‚°ì¶œ ë°©ì‹(LLM/ê·œì¹™)ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                st.dataframe(make_arrow_safe(df_score), use_container_width=True, height=360)

                st.subheader("íšŒì°¨ë³„ í‰ê·  ì ìˆ˜")
                if df_round.empty:
                    st.info("íšŒì°¨ ìš”ì•½ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.dataframe(make_arrow_safe(df_round), use_container_width=True, height=220)

                st.subheader("ì—ì´ì „íŠ¸ë³„ ìµœì¢… ì ìˆ˜")
                if df_agent.empty:
                    st.info("ì—ì´ì „íŠ¸ ìš”ì•½ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.dataframe(make_arrow_safe(df_agent), use_container_width=True, height=220)

                st.subheader("ë‹¤ìš´ë¡œë“œ")
                score_xlsx = dataframes_to_excel_bytes(
                    {
                        source_sheet_name: source_df,
                        "aqb_scores_v1_2": df_score,
                        "aqb_round_summary": df_round,
                        "aqb_agent_summary": df_agent,
                        "aqb_precheck": df_precheck,
                    }
                )
                st.download_button(
                    "ğŸ“¥ í’ˆì§ˆ ì ìˆ˜ Excel ë‹¤ìš´ë¡œë“œ (ì›ë³¸+ì ìˆ˜/ìš”ì•½/í”„ë¦¬ì²´í¬ ì‹œíŠ¸)",
                    data=score_xlsx,
                    file_name=f"aqb_quality_scores_{env}_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key="download_quality_score",
                )

    # --------------------------------------------
    # Tab 1: ë²”ìš© í…ŒìŠ¤íŠ¸
    # --------------------------------------------
    with tab_generic:
        st.subheader("ë²”ìš© í…ŒìŠ¤íŠ¸")
        st.caption("ë²”ìš© ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸. í•„ìˆ˜ ì»¬ëŸ¼: `ì§ˆì˜`. ì„ íƒ ì»¬ëŸ¼: `LLM í‰ê°€ê¸°ì¤€`, `ê²€ì¦ í•„ë“œ`, `ê¸°ëŒ€ê°’`")

        # CSV í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ
        st.download_button(
            "â¬‡ï¸ ë²”ìš© í…ŒìŠ¤íŠ¸ CSV ì–‘ì‹ ë‹¤ìš´ë¡œë“œ",
            data=build_generic_csv_template(),
            file_name="ë²”ìš©_í…ŒìŠ¤íŠ¸_í…œí”Œë¦¿.csv",
            mime="text/csv",
            key="download_generic_template"
        )

        # ì…ë ¥ ë°©ì‹ ì„ íƒ
        input_mode = st.radio("ì…ë ¥ ë°©ì‹", ["CSV ì—…ë¡œë“œ", "ì§ì ‘ ì…ë ¥"], horizontal=True)

        generic_df: Optional[pd.DataFrame] = None

        if input_mode == "CSV ì—…ë¡œë“œ":
            up_generic = st.file_uploader("ë²”ìš© í…ŒìŠ¤íŠ¸ CSV", type=["csv"], key="generic_csv")
            if up_generic is not None:
                try:
                    generic_df = pd.read_csv(up_generic, encoding="utf-8")
                except Exception:
                    generic_df = pd.read_csv(up_generic, encoding="utf-8-sig")
                generic_df = normalize_columns(generic_df)
        else:
            # ì§ì ‘ ì…ë ¥ (4ê°œ í•„ë“œ)
            st.markdown("**ì§ˆì˜ ì…ë ¥**")
            direct_query = st.text_area("ì§ˆì˜", placeholder="ì—ì´ì „íŠ¸ì—ê²Œ ë³´ë‚¼ ì§ˆì˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”", height=100)
            direct_criteria = st.text_area("LLM í‰ê°€ê¸°ì¤€", placeholder="í‰ê°€ ê¸°ì¤€ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì •í™•í•œ ìˆ˜ì¹˜ í¬í•¨ ì—¬ë¶€, ì‘ë‹µ í˜•ì‹ ë“±)", height=100)
            col_field, col_expect = st.columns(2)
            with col_field:
                direct_field = st.text_input("ê²€ì¦ í•„ë“œ", placeholder="ì˜ˆ: assistantMessage, dataUIList[0].uiValue.buttonUrl")
            with col_expect:
                direct_expected = st.text_input("ê¸°ëŒ€ê°’", placeholder="ì‘ë‹µì— í¬í•¨ë˜ì–´ì•¼ í•  ë¬¸ìì—´")

            if direct_query.strip():
                generic_df = pd.DataFrame([{
                    "ì§ˆì˜": direct_query.strip(),
                    "LLM í‰ê°€ê¸°ì¤€": direct_criteria.strip(),
                    "ê²€ì¦ í•„ë“œ": direct_field.strip(),
                    "ê¸°ëŒ€ê°’": direct_expected.strip(),
                }])

        if generic_df is not None:
            # ID ìë™ ìƒì„± (CSVì— ID ì»¬ëŸ¼ ì—†ìœ¼ë©´)
            if "ID" not in generic_df.columns:
                generic_df.insert(0, "ID", [f"Q-{i+1}" for i in range(len(generic_df))])

            # ì„ íƒ ì»¬ëŸ¼ ê¸°ë³¸ê°’ ë³´ì¥
            for _col_name in ("LLM í‰ê°€ê¸°ì¤€", "ê²€ì¦ í•„ë“œ", "ê¸°ëŒ€ê°’"):
                if _col_name not in generic_df.columns:
                    generic_df[_col_name] = ""
            generic_df = generic_df.fillna("")

            st.session_state["generic_input_df"] = generic_df.copy()
            st.write("ë¯¸ë¦¬ë³´ê¸°", generic_df.head(10))

            # API ì„¤ì • (ë²”ìš© í…ŒìŠ¤íŠ¸ìš©)
            st.subheader("API ì„¤ì • (ì„ íƒ)")
            col_ctx_g, col_target_g = st.columns(2)

            with col_ctx_g:
                use_generic_context = st.checkbox("Context ì‚¬ìš©", value=False, key="generic_context_check")
                generic_context_obj: Optional[Dict[str, Any]] = None
                if use_generic_context:
                    generic_context_input = st.text_area(
                        "Context (JSON í˜•ì‹)",
                        value='{"recruitPlanId": 123}',
                        height=80,
                        key="generic_context_input"
                    )
                    try:
                        generic_context_obj = json.loads(generic_context_input)
                        st.success("âœ… JSON íŒŒì‹± ì„±ê³µ")
                    except json.JSONDecodeError:
                        st.error("JSON íŒŒì‹± ì˜¤ë¥˜")
                        generic_context_obj = None

            with col_target_g:
                use_generic_target = st.checkbox("targetAssistant ì§€ì •", value=False, key="generic_target_check")
                generic_target_assistant: Optional[str] = None
                if use_generic_target:
                    generic_target_assistant = st.text_input(
                        "targetAssistant",
                        value="RECRUIT_PLAN_ASSISTANT",
                        key="generic_target_input",
                        help='ì˜ˆ: RECRUIT_PLAN_ASSISTANT, RECRUIT_PLAN_CREATE_ASSISTANT'
                    )

            # â”€â”€ ë²„íŠ¼ 2ê°œ: 1ë‹¨ê³„ / 2ë‹¨ê³„ â”€â”€
            col_btn1, col_btn2 = st.columns(2)
            with col_btn1:
                run_step1 = st.button("1ë‹¨ê³„: ì§ˆì˜ ë³´ë‚´ê¸°", key="run_generic_step1")
            with col_btn2:
                run_step2 = st.button("2ë‹¨ê³„: í‰ê°€í•˜ê¸°", key="run_generic_step2")

            progress_generic = st.progress(0)
            progress_generic_text = st.empty()

            # â”€â”€ Step 1: ì§ˆì˜ ë³´ë‚´ê¸° (ë³‘ë ¬) â”€â”€
            if run_step1:
                if not (base_url and bearer and cms and mrs):
                    st.error("ATS ì„¤ì •ê³¼ í† í°ì„ ì…ë ¥í•˜ì„¸ìš”.")
                else:
                    async def run_generic_queries():
                        nonlocal progress_generic, progress_generic_text
                        client = ApplicantAgentClient(
                            base_url=base_url,
                            bearer_token=bearer,
                            cms_token=cms,
                            mrs_session=mrs,
                            origin=origin,
                            referer=referer,
                            max_parallel=agent_parallel,
                        )
                        connector = aiohttp.TCPConnector(limit=50, ssl=False)
                        _timeout = aiohttp.ClientTimeout(total=120)

                        input_df = st.session_state["generic_input_df"]
                        total = len(input_df)
                        done_count = 0
                        start_time = time.time()

                        # ê²°ê³¼ DataFrame ì¤€ë¹„ (ì…ë ¥ ì»¬ëŸ¼ + ì¶œë ¥ ì»¬ëŸ¼)
                        res_df = input_df.copy()
                        for _c in ("ì‘ë‹µ", "ì‘ë‹µ ì‹œê°„(ì´ˆ)", "ì‹¤í–‰ í”„ë¡œì„¸ìŠ¤", "ì˜¤ë¥˜", "raw"):
                            res_df[_c] = ""

                        async with aiohttp.ClientSession(connector=connector, timeout=_timeout) as session:
                            async def _run_one(idx: int):
                                async with client.semaphore:
                                    query = str(res_df.loc[idx, "ì§ˆì˜"])
                                    sync_result = await client.test_orchestrator_sync(
                                        session,
                                        query,
                                        conversation_id=None,
                                        context=generic_context_obj,
                                        target_assistant=generic_target_assistant,
                                    )
                                    if sync_result.get("error"):
                                        return {"idx": idx, "err": str(sync_result.get("error")), "sse": None}
                                    return {"idx": idx, "err": "", "sse": sync_result}

                            tasks = []
                            for i in range(total):
                                tasks.append(asyncio.create_task(_run_one(i)))

                            for fut in asyncio.as_completed(tasks):
                                result = await fut
                                idx = result["idx"]
                                err = result["err"]
                                sse = result["sse"]

                                if sse is None:
                                    # ë™ê¸°ì‹ í…ŒìŠ¤íŠ¸ API í˜¸ì¶œ ì‹¤íŒ¨
                                    res_df.at[idx, "ì˜¤ë¥˜"] = err
                                else:
                                    # ì‹¤í–‰ í”„ë¡œì„¸ìŠ¤ ìš”ì•½
                                    exec_summary = ""
                                    for ep in sse.get("execution_processes", []):
                                        msg_summary = ep.get("messageSummary", "")
                                        if msg_summary:
                                            step_ms = ep.get("ms")
                                            try:
                                                step_ms_float = float(step_ms)
                                            except Exception:
                                                step_ms_float = None
                                            if step_ms_float is not None:
                                                exec_summary += f"[{msg_summary} ({step_ms_float:.1f}ms)] "
                                            else:
                                                exec_summary += f"[{msg_summary}] "

                                    res_df.at[idx, "ì‘ë‹µ"] = sse.get("assistant_message", "")
                                    rt = sse.get("response_time_sec")
                                    res_df.at[idx, "ì‘ë‹µ ì‹œê°„(ì´ˆ)"] = round(rt, 2) if rt else ""
                                    res_df.at[idx, "ì‹¤í–‰ í”„ë¡œì„¸ìŠ¤"] = exec_summary.strip()
                                    res_df.at[idx, "ì˜¤ë¥˜"] = sse.get("error", "")
                                    # LLM/ë¡œì§ í‰ê°€ì—ì„œ "ì›ë³¸ ì‘ë‹µ"ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡
                                    # ì¶•ì•½ payload + worker ì›ë³¸/ìš”ì•½ì„ í•¨ê»˜ ì €ì¥
                                    res_df.at[idx, "raw"] = json.dumps(
                                        {
                                            "assistantMessage": sse.get("assistant_message"),
                                            "dataUIList": sse.get("data_ui_list"),
                                            "guideList": sse.get("guide_list"),
                                            "execution_processes": sse.get("execution_processes", []),
                                            "worker": sse.get("workers", []),
                                            "workerMsMap": sse.get("worker_ms_map", {}),
                                            "conversation_id": sse.get("conversation_id"),
                                            "response_time_sec": sse.get("response_time_sec"),
                                            "error": sse.get("error", ""),
                                        },
                                        ensure_ascii=False,
                                        default=str,
                                    )

                                done_count += 1
                                elapsed = time.time() - start_time
                                progress_generic.progress(min(1.0, done_count / total))
                                if done_count > 0 and elapsed > 0:
                                    remaining = (total - done_count) * (elapsed / done_count)
                                    progress_generic_text.markdown(
                                        f"**ì§„í–‰** {done_count}/{total} | "
                                        f"**ì´ ê²½ê³¼ ì‹œê°„** {elapsed:.1f}ì´ˆ (ì•½ {remaining:.0f}ì´ˆ ë‚¨ìŒ)"
                                    )

                        return res_df

                    result_df = run_async(run_generic_queries())
                    st.session_state["generic_results_df"] = result_df
                    st.session_state["generic_df"] = result_df.copy()
                    st.success("1ë‹¨ê³„ ì™„ë£Œ: ì§ˆì˜ ì‘ë‹µ ìˆ˜ì§‘ ì™„ë£Œ")

            # â”€â”€ Step 2: í‰ê°€í•˜ê¸° â”€â”€
            if run_step2:
                if "generic_results_df" not in st.session_state:
                    st.error("ë¨¼ì € 1ë‹¨ê³„(ì§ˆì˜ ë³´ë‚´ê¸°)ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
                else:
                    eval_df = st.session_state["generic_results_df"].copy()

                    # (A) ë¡œì§ í‰ê°€ (ë™ê¸°, ì¦‰ì‹œ)
                    if "ë¡œì§ ê²€ì¦ê²°ê³¼" not in eval_df.columns:
                        eval_df["ë¡œì§ ê²€ì¦ê²°ê³¼"] = ""
                    for idx in range(len(eval_df)):
                        field_path = str(eval_df.at[idx, "ê²€ì¦ í•„ë“œ"]).strip()
                        expected = str(eval_df.at[idx, "ê¸°ëŒ€ê°’"]).strip()
                        if field_path and expected and field_path.lower() != "nan" and expected.lower() != "nan":
                            raw_str = str(eval_df.at[idx, "raw"])
                            eval_df.at[idx, "ë¡œì§ ê²€ì¦ê²°ê³¼"] = run_logic_check(raw_str, field_path, expected)

                    # (B) LLM í‰ê°€ (ë¹„ë™ê¸°, ë³‘ë ¬)
                    if "LLM í‰ê°€ê²°ê³¼" not in eval_df.columns:
                        eval_df["LLM í‰ê°€ê²°ê³¼"] = ""

                    # LLM í‰ê°€ ëŒ€ìƒ ì¸ë±ìŠ¤ ìˆ˜ì§‘
                    llm_targets = []
                    for idx in range(len(eval_df)):
                        criteria = str(eval_df.at[idx, "LLM í‰ê°€ê¸°ì¤€"]).strip()
                        if criteria and criteria.lower() != "nan":
                            llm_targets.append(idx)

                    if llm_targets and openai_key:
                        async def run_generic_llm_eval():
                            sem = asyncio.Semaphore(judge_parallel)
                            _timeout = aiohttp.ClientTimeout(total=120)

                            async with aiohttp.ClientSession(timeout=_timeout) as session:
                                async def eval_one(idx: int):
                                    async with sem:
                                        row_err = str(eval_df.at[idx, "ì˜¤ë¥˜"]).strip()
                                        if row_err and row_err.lower() != "nan":
                                            return idx, "í‰ê°€ ë¶ˆê°€ (í˜¸ì¶œ ì˜¤ë¥˜)"

                                        criteria = str(eval_df.at[idx, "LLM í‰ê°€ê¸°ì¤€"])
                                        response_raw = str(eval_df.at[idx, "raw"])
                                        query = str(eval_df.at[idx, "ì§ˆì˜"])

                                        eval_prompt = f"""ë‹¤ìŒ ì§ˆì˜ì— ëŒ€í•œ ì—ì´ì „íŠ¸ ì‘ë‹µì„ í‰ê°€í•˜ì„¸ìš”.

ì§ˆì˜: {query}

ì‘ë‹µ(raw JSON): {response_raw[:max_chars]}

í‰ê°€ ê¸°ì¤€: {criteria}

í‰ê°€ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:
{{"score": 0-5, "passed": true/false, "reason": "í‰ê°€ ì‚¬ìœ "}}
"""
                                        result, _usage, err = await openai_judge_with_retry(
                                            session, openai_key, openai_model, eval_prompt
                                        )
                                        if result:
                                            return idx, json.dumps(result, ensure_ascii=False)
                                        return idx, f"í‰ê°€ ì‹¤íŒ¨: {err}"

                                eval_tasks = [asyncio.create_task(eval_one(i)) for i in llm_targets]
                                for fut in asyncio.as_completed(eval_tasks):
                                    idx, eval_result = await fut
                                    eval_df.at[idx, "LLM í‰ê°€ê²°ê³¼"] = eval_result

                        run_async(run_generic_llm_eval())
                    elif llm_targets and not openai_key:
                        st.warning("LLM í‰ê°€ ëŒ€ìƒì´ ìˆìœ¼ë‚˜ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

                    st.session_state["generic_df"] = eval_df
                    st.success("2ë‹¨ê³„ ì™„ë£Œ: í‰ê°€ ì™„ë£Œ")

            # â”€â”€ ê²°ê³¼ í‘œì‹œ â”€â”€
            if "generic_df" in st.session_state:
                df_generic_out = st.session_state["generic_df"]
                st.subheader("ê²°ê³¼ í…Œì´ë¸”")

                # ìš”ì•½ ë©”íŠ¸ë¦­
                total_q = len(df_generic_out)
                logic_col = df_generic_out.get("ë¡œì§ ê²€ì¦ê²°ê³¼")
                logic_pass = 0
                logic_fail = 0
                if logic_col is not None:
                    logic_pass = int(logic_col.astype(str).str.startswith("PASS").sum())
                    logic_fail = int(logic_col.astype(str).str.startswith("FAIL").sum())
                llm_col = df_generic_out.get("LLM í‰ê°€ê²°ê³¼")
                llm_done = 0
                if llm_col is not None:
                    llm_done = int((llm_col.astype(str).str.strip() != "").sum())
                err_col = df_generic_out.get("ì˜¤ë¥˜")
                err_count = 0
                if err_col is not None:
                    err_count = int((err_col.astype(str).str.strip() != "").sum()
                                    - (err_col.astype(str).str.strip().str.lower() == "nan").sum())

                mc1, mc2, mc3, mc4 = st.columns(4)
                mc1.metric("ì´ ì§ˆì˜ ìˆ˜", total_q)
                mc2.metric("ë¡œì§ PASS / FAIL", f"{logic_pass} / {logic_fail}")
                mc3.metric("LLM í‰ê°€ ì™„ë£Œ", llm_done)
                mc4.metric("ì˜¤ë¥˜ ê±´ìˆ˜", max(0, err_count))

                st.dataframe(make_arrow_safe(df_generic_out), use_container_width=True, height=420)

                xlsx_bytes = dataframe_to_excel_bytes(df_generic_out, sheet_name="generic_results")
                st.download_button(
                    "ğŸ“¥ ë²”ìš© í…ŒìŠ¤íŠ¸ ê²°ê³¼ Excel ë‹¤ìš´ë¡œë“œ",
                    data=xlsx_bytes,
                    file_name=f"generic_test_results_{env}_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key="download_generic"
                )
        else:
            st.info("CSVë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”.")

    # --------------------------------------------
    # Tab 3: ì´ë™ ì—ì´ì „íŠ¸ ê²€ì¦
    # --------------------------------------------
    with tab_url:
        st.subheader("ì´ë™ ì—ì´ì „íŠ¸ ê²€ì¦")
        st.caption("CSV ì»¬ëŸ¼ ì˜ˆì‹œ: ID, ì§ˆì˜, ê¸°ëŒ€URL (ê¸°ëŒ€URLì€ ë¶€ë¶„ë¬¸ìì—´ ë˜ëŠ” /ì •ê·œì‹/ í˜•íƒœ ì§€ì›)")

        # CSV í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ
        st.download_button(
            "â¬‡ï¸ ì´ë™ ì—ì´ì „íŠ¸ ê²€ì¦ CSV ì–‘ì‹ ë‹¤ìš´ë¡œë“œ",
            data=build_url_csv_template(),
            file_name="ì´ë™_ì—ì´ì „íŠ¸_ê²€ì¦_í…œí”Œë¦¿.csv",
            mime="text/csv",
            key="download_url_template"
        )

        up3 = st.file_uploader("URL í…ŒìŠ¤íŠ¸ CSV", type=["csv"], key="urlcsv")

        if up3 is None:
            st.info("URL í…ŒìŠ¤íŠ¸ìš© CSVë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        else:
            try:
                df3 = pd.read_csv(up3, encoding="utf-8")
            except Exception:
                df3 = pd.read_csv(up3, encoding="utf-8-sig")
            df3 = normalize_columns(df3)

            st.write("ë¯¸ë¦¬ë³´ê¸°", df3.head(10))

            if not (base_url and origin and referer and bearer and cms and mrs):
                st.warning("ì¢Œì¸¡ ì„¤ì •ì—ì„œ ATS í™˜ê²½/í† í°ì„ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                tester = UrlAgentTester(
                    base_url=base_url,
                    bearer_token=bearer,
                    cms_token=cms,
                    mrs_session=mrs,
                    origin=origin,
                    referer=referer,
                    max_parallel=agent_parallel,
                )

                rows = []
                for _, r in df3.iterrows():
                    rows.append(
                        {
                            "ID": str(r.get("ID", "")),
                            "ì§ˆì˜": str(r.get("ì§ˆì˜", "")),
                            "ê¸°ëŒ€URL": str(r.get("ê¸°ëŒ€URL", "")),
                        }
                    )

                run_url = st.button("URL í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
                progress3 = st.progress(0)
                log3 = st.empty()

                def progress_cb3(done: int, total: int, msg: str):
                    if total > 0:
                        progress3.progress(min(1.0, done / total))
                    log3.write(msg)

                if run_url:
                    df_url_out = run_async(run_url_tests_async(rows, tester, progress_cb=progress_cb3))
                    st.session_state["url_df"] = df_url_out
                    st.success("URL í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

                if "url_df" in st.session_state:
                    df_url_out = st.session_state["url_df"]
                    st.dataframe(make_arrow_safe(df_url_out), use_container_width=True, height=420)

                    xlsx_bytes = dataframe_to_excel_bytes(df_url_out, sheet_name="url_results")
                    st.download_button(
                        "ğŸ“¥ URL ê²°ê³¼ Excel ë‹¤ìš´ë¡œë“œ",
                        data=xlsx_bytes,
                        file_name=f"url_agent_results_{env}_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    )

    # --------------------------------------------
    # Tab 4: í”„ë¡¬í”„íŠ¸ ê´€ë¦¬
    # --------------------------------------------
    with tab_prompt:
        st.subheader("Worker í”„ë¡¬í”„íŠ¸ ê´€ë¦¬")
        st.caption("Workerë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì¡°íšŒ, ìˆ˜ì •, ì´ˆê¸°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if "prompt_result" not in st.session_state:
            st.session_state["prompt_result"] = None
        if "prompt_worker" not in st.session_state:
            st.session_state["prompt_worker"] = WORKER_TYPES[0]
        if "prompt_editing" not in st.session_state:
            st.session_state["prompt_editing"] = False

        # Worker íƒ€ì… ì„ íƒ
        selected_worker = st.selectbox(
            "Worker íƒ€ì… ì„ íƒ",
            WORKER_TYPES,
            index=WORKER_TYPES.index(st.session_state["prompt_worker"]) if st.session_state["prompt_worker"] in WORKER_TYPES else 0,
            format_func=lambda x: f"{x} - {WORKER_DESCRIPTIONS.get(x, '')}",
            key="prompt_worker_select",
        )

        # Worker ì„ íƒì´ ë³€ê²½ë˜ë©´ ì´ì „ ê²°ê³¼ ì´ˆê¸°í™”
        if st.session_state["prompt_worker"] != selected_worker:
            st.session_state["prompt_result"] = None
            st.session_state["prompt_worker"] = selected_worker
            st.session_state["prompt_editing"] = False

        # í”„ë¡¬í”„íŠ¸ ì¡°íšŒ ë° ì´ˆê¸°í™” ë²„íŠ¼
        col_btn1, col_btn2 = st.columns(2)
        with col_btn1:
            if st.button("ğŸ” í”„ë¡¬í”„íŠ¸ ì¡°íšŒ", key="prompt_get"):
                if not base_url:
                    st.error("ì‚¬ì´ë“œë°”ì—ì„œ í™˜ê²½ì„ ì„ íƒí•˜ì„¸ìš”.")
                else:
                    with st.spinner("í”„ë¡¬í”„íŠ¸ ì¡°íšŒ ì¤‘..."):
                        try:
                            client = AxPromptApiClient(
                                base_url=base_url,
                                environment=env,
                                retention_token=bearer if bearer else None,
                                mrs_session=mrs if mrs else None,
                                cms_access_token=cms if cms else None,
                            )
                            result = client.get_prompt(selected_worker)
                            st.session_state["prompt_result"] = result
                            st.session_state["prompt_worker"] = selected_worker
                            st.session_state["prompt_editing"] = False
                            st.success("í”„ë¡¬í”„íŠ¸ ì¡°íšŒ ì™„ë£Œ!")
                            st.rerun()
                        except Exception as e:
                            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

        with col_btn2:
            if st.button("ğŸ”„ í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™”", key="prompt_reset"):
                if not base_url:
                    st.error("ì‚¬ì´ë“œë°”ì—ì„œ í™˜ê²½ì„ ì„ íƒí•˜ì„¸ìš”.")
                else:
                    with st.spinner("í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™” ì¤‘..."):
                        try:
                            client = AxPromptApiClient(
                                base_url=base_url,
                                environment=env,
                                retention_token=bearer if bearer else None,
                                mrs_session=mrs if mrs else None,
                                cms_access_token=cms if cms else None,
                            )
                            result = client.reset_prompt(selected_worker)
                            before_len = safe_len(result.before)
                            after_len = safe_len(result.after)
                            st.success("í”„ë¡¬í”„íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ!")
                            st.info(f"ë³€ê²½ ì „: {before_len}ì -> ë³€ê²½ í›„: {after_len}ì")
                            st.session_state["prompt_result"] = result
                            st.session_state["prompt_worker"] = selected_worker
                            st.session_state["prompt_editing"] = False
                            st.rerun()
                        except Exception as e:
                            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

        st.divider()

        # í”„ë¡¬í”„íŠ¸ ì¡°íšŒ ê²°ê³¼ í‘œì‹œ
        if st.session_state["prompt_result"] is not None:
            result = st.session_state["prompt_result"]
            worker = st.session_state.get("prompt_worker", "Unknown")

            # í˜„ì¬ ì„ íƒëœ Workerì™€ ê²°ê³¼ì˜ Workerê°€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
            if worker != selected_worker:
                st.info("Worker íƒ€ì…ì„ ì„ íƒí•˜ê³  'í”„ë¡¬í”„íŠ¸ ì¡°íšŒ' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
            else:
                before_text = result.before if result.before is not None else ""
                after_text = result.after if result.after is not None else ""

                # ë³€ê²½ ì „/í˜„ì¬ í”„ë¡¬í”„íŠ¸ë¥¼ 2ì—´ë¡œ í‘œì‹œ
                st.markdown("### í”„ë¡¬í”„íŠ¸ ë¹„êµ")
                col_before, col_after = st.columns(2)

                with col_before:
                    st.markdown("#### ë³€ê²½ ì „ í”„ë¡¬í”„íŠ¸")
                    st.text_area(
                        "ë³€ê²½ ì „",
                        value=before_text,
                        height=400,
                        disabled=True,
                        key="prompt_before",
                    )
                    st.caption(f"ê¸¸ì´: {safe_len(before_text)}ì")

                with col_after:
                    st.markdown("#### í˜„ì¬ í”„ë¡¬í”„íŠ¸")
                    st.text_area(
                        "í˜„ì¬",
                        value=after_text,
                        height=400,
                        disabled=True,
                        key="prompt_after",
                    )
                    st.caption(f"ê¸¸ì´: {safe_len(after_text)}ì")

                st.divider()

                # í”„ë¡¬í”„íŠ¸ ìˆ˜ì • ì„¹ì…˜
                st.markdown("### í”„ë¡¬í”„íŠ¸ ìˆ˜ì •")

                # ìˆ˜ì • ëª¨ë“œ í† ê¸€ ë²„íŠ¼
                if not st.session_state["prompt_editing"]:
                    if st.button("âœï¸ í”„ë¡¬í”„íŠ¸ ìˆ˜ì • ì‹œì‘", key="prompt_edit_start"):
                        st.session_state["prompt_editing"] = True
                        st.rerun()
                else:
                    # ìˆ˜ì • ì˜ì—­
                    st.info("í˜„ì¬ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”. ë³€ê²½ ì‚¬í•­ì€ ì €ì¥ ì‹œ ì ìš©ë©ë‹ˆë‹¤.")

                    new_prompt = st.text_area(
                        "ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ì…ë ¥",
                        value=after_text,
                        height=400,
                        help="í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•œ í›„ 'í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.",
                        key="prompt_new_input",
                    )

                    # ë³€ê²½ ì‚¬í•­ ìš”ì•½
                    if new_prompt != after_text:
                        diff_len = len(new_prompt) - len(after_text)
                        diff_sign = "+" if diff_len > 0 else ""
                        st.info(f"ë³€ê²½ ì‚¬í•­: {len(after_text)}ì -> {len(new_prompt)}ì ({diff_sign}{diff_len}ì)")

                    # ë²„íŠ¼ ì˜ì—­
                    col_save, col_cancel = st.columns(2)
                    with col_save:
                        if st.button("ğŸ’¾ í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸", key="prompt_update"):
                            with st.spinner("í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸ ì¤‘..."):
                                try:
                                    client = AxPromptApiClient(
                                        base_url=base_url,
                                        environment=env,
                                        retention_token=bearer if bearer else None,
                                        mrs_session=mrs if mrs else None,
                                        cms_access_token=cms if cms else None,
                                    )
                                    update_result = client.update_prompt(worker, new_prompt)
                                    before_len = safe_len(update_result.before)
                                    after_len = safe_len(update_result.after)
                                    st.success("í”„ë¡¬í”„íŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
                                    st.info(f"ë³€ê²½ ì „: {before_len}ì -> ë³€ê²½ í›„: {after_len}ì")
                                    st.session_state["prompt_result"] = update_result
                                    st.session_state["prompt_editing"] = False
                                    st.rerun()
                                except Exception as e:
                                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

                    with col_cancel:
                        if st.button("âŒ ìˆ˜ì • ì·¨ì†Œ", key="prompt_cancel"):
                            st.session_state["prompt_editing"] = False
                            st.rerun()
        else:
            st.info("Worker íƒ€ì…ì„ ì„ íƒí•˜ê³  'í”„ë¡¬í”„íŠ¸ ì¡°íšŒ' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()
