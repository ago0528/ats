# src/ats/ax/test/langgraph_sample/agent_flow_gpt5_direct.py
"""
GPT-5 ëª¨ë¸ì„ ì§ì ‘ OpenAI Clientë¡œ ì‚¬ìš©í•˜ëŠ” ë²„ì „
ì°¸ê³ : https://community.openai.com/t/gpt-5-models-temperature/1337957

GPT-5ëŠ” reasoning ëª¨ë¸ë¡œ temperature íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
LangChainì˜ ChatOpenAIê°€ ìë™ìœ¼ë¡œ temperatureë¥¼ ì¶”ê°€í•˜ë¯€ë¡œ,
ì§ì ‘ OpenAI clientë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""

import operator
import os
from typing import TypedDict, Annotated, Sequence, List, Dict, Any
from openai import OpenAI

from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, BaseMessage
from langchain_core.tools import tool
from dotenv import load_dotenv

load_dotenv()

# OpenAI Client ì´ˆê¸°í™”
client = OpenAI()

# ==============================================================================
# 1. State ì •ì˜
# ==============================================================================
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], operator.add]
    progress_log: Annotated[List[Dict[str, Any]], operator.add]

# ==============================================================================
# 2. Tools ì •ì˜
# ==============================================================================
@tool
def report_progress(
    stage: str,
    action: str,
    progress: int,
    details: str
) -> str:
    """ì‘ì—… ì§„í–‰ ìƒí™©ì„ ì‚¬ìš©ìì—ê²Œ ë³´ê³ í•©ë‹ˆë‹¤."""
    print(f"\nğŸ“Š [{progress}%] {stage.upper()}: {action}")
    print(f"   ğŸ’¬ {details}\n")
    return f"ì§„í–‰ ìƒí™©ì´ ì‚¬ìš©ìì—ê²Œ ë³´ê³ ë˜ì—ˆìŠµë‹ˆë‹¤: {action} ({progress}%)"

@tool
def search_conversations(query: str) -> str:
    """ê³¼ê±° ëŒ€í™” ë‚´ì—­ì´ë‚˜ í”„ë¡œì íŠ¸ íˆìŠ¤í† ë¦¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    return f"'{query}' ê´€ë ¨ ëŒ€í™” 3ê±´ ë°œê²¬: ë³‘ì› ìƒì„¸ í˜ì´ì§€ UX, í•„í„°ë§ ì‹œìŠ¤í…œ, í”„ë¡œí•„ ì„¤ê³„"

@tool
def read_document(path: str) -> str:
    """ì§€ì •ëœ ê²½ë¡œì˜ ë¬¸ì„œë¥¼ ì½ì–´ì„œ ë‚´ìš©ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return f"{path} ë¬¸ì„œ ë‚´ìš© ë¡œë“œ ì™„ë£Œ"

# Tool ìŠ¤í‚¤ë§ˆ ìƒì„±
def get_tool_schemas():
    """LangChain toolsë¥¼ OpenAI function calling í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    tools = [report_progress, search_conversations, read_document]
    return [
        {
            "type": "function",
            "function": {
                "name": t.name,
                "description": t.description,
                "parameters": {
                    "type": "object",
                    "properties": {
                        arg_name: {
                            "type": "string",
                            "description": f"{arg_name} parameter"
                        }
                        for arg_name in t.args
                    },
                    "required": list(t.args.keys())
                }
            }
        }
        for t in tools
    ]

# ==============================================================================
# 3. Nodes ì •ì˜
# ==============================================================================
def agent_node(state: AgentState):
    """Agent ë…¸ë“œ: GPT-5ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•©ë‹ˆë‹¤."""
    if not os.getenv("OPENAI_API_KEY"):
        print("âš ï¸ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # LangChain ë©”ì‹œì§€ë¥¼ OpenAI í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    messages = []
    for msg in state["messages"]:
        if isinstance(msg, HumanMessage):
            messages.append({"role": "user", "content": msg.content})
        elif isinstance(msg, AIMessage):
            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                # Tool callsê°€ ìˆëŠ” ê²½ìš°
                tool_calls = [
                    {
                        "id": tc['id'],
                        "type": "function",
                        "function": {
                            "name": tc['name'],
                            "arguments": str(tc['args'])
                        }
                    }
                    for tc in msg.tool_calls
                ]
                messages.append({
                    "role": "assistant",
                    "content": msg.content or "",
                    "tool_calls": tool_calls
                })
            else:
                messages.append({"role": "assistant", "content": msg.content})
        elif isinstance(msg, ToolMessage):
            messages.append({
                "role": "tool",
                "tool_call_id": msg.tool_call_id,
                "content": msg.content
            })

    # GPT-5 API í˜¸ì¶œ (temperature íŒŒë¼ë¯¸í„° ì œì™¸)
    # ì°¸ê³ : https://community.openai.com/t/gpt-5-models-temperature/1337957
    try:
        completion = client.chat.completions.create(
            model="gpt-5-nano",
            messages=messages,
            tools=get_tool_schemas()
            # temperature íŒŒë¼ë¯¸í„°ë¥¼ ëª…ì‹œí•˜ì§€ ì•ŠìŒ (GPT-5 ìš”êµ¬ì‚¬í•­)
        )
        
        response_message = completion.choices[0].message
        
        # OpenAI ì‘ë‹µì„ LangChain AIMessageë¡œ ë³€í™˜
        if response_message.tool_calls:
            tool_calls = [
                {
                    'name': tc.function.name,
                    'args': eval(tc.function.arguments),  # JSON string to dict
                    'id': tc.id,
                    'type': 'tool_call'
                }
                for tc in response_message.tool_calls
            ]
            ai_msg = AIMessage(
                content=response_message.content or "",
                tool_calls=tool_calls
            )
        else:
            ai_msg = AIMessage(content=response_message.content)
        
        return {"messages": [ai_msg]}
        
    except Exception as e:
        print(f"âŒ GPT-5 API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        raise

def tool_node(state: AgentState):
    """Tools ë…¸ë“œ: Agentê°€ ì„ íƒí•œ ë„êµ¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    tools = [report_progress, search_conversations, read_document]
    tool_executor = ToolNode(tools)
    result = tool_executor.invoke(state)

    last_message = state["messages"][-1]
    progress_entries = []
    
    if hasattr(last_message, 'tool_calls'):
        for tool_call in last_message.tool_calls:
            if tool_call['name'] == 'report_progress':
                progress_entry = {
                    'stage': tool_call['args'].get('stage'),
                    'action': tool_call['args'].get('action'),
                    'progress': tool_call['args'].get('progress'),
                    'details': tool_call['args'].get('details')
                }
                progress_entries.append(progress_entry)
    
    output = {"messages": result["messages"]}
    if progress_entries:
        output["progress_log"] = progress_entries

    return output

# ==============================================================================
# 4. Graph êµ¬ì„±
# ==============================================================================
def should_continue(state: AgentState):
    """ì¡°ê±´ë¶€ ì—£ì§€: ë„êµ¬ í˜¸ì¶œì´ ìˆìœ¼ë©´ Tools ë…¸ë“œë¡œ, ì—†ìœ¼ë©´ ì¢…ë£Œ."""
    last_message = state["messages"][-1]
    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        return "tools"
    return END

def create_agent_graph():
    """LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ìƒì„±í•˜ê³  ì»´íŒŒì¼í•©ë‹ˆë‹¤."""
    workflow = StateGraph(AgentState)

    workflow.add_node("agent", agent_node)
    workflow.add_node("tools", tool_node)
    workflow.set_entry_point("agent")
    workflow.add_conditional_edges(
        "agent",
        should_continue,
        {"tools": "tools", END: END}
    )
    workflow.add_edge("tools", "agent")

    return workflow.compile()

# ==============================================================================
# 5. ì‹¤í–‰ ë¡œì§
# ==============================================================================
def run_agent_with_progress(user_query: str):
    """Agentë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    system_prompt = """
ë‹¹ì‹ ì€ ë©”ë””ì»¬ì¡ë‹¤ í”„ë¡œë•íŠ¸ ë§¤ë‹ˆì €ì˜ ì—…ë¬´ë¥¼ ë•ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ì¤‘ìš”**: ì‘ì—…ì„ ìˆ˜í–‰í•  ë•Œë§ˆë‹¤ report_progress ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬
ì‚¬ìš©ìì—ê²Œ ì§„í–‰ ìƒí™©ì„ ì•Œë ¤ì£¼ì„¸ìš”.

ë³´ê³  ì‹œì :
1. ìƒˆë¡œìš´ ë‹¨ê³„ ì‹œì‘ ì‹œ
2. ì¤‘ìš”í•œ ë„êµ¬ í˜¸ì¶œ ì „í›„
3. ì˜ë¯¸ìˆëŠ” ê²°ê³¼ ë„ì¶œ ì‹œ

ì˜ˆì‹œ:
- report_progress(stage="planning", action="ì‘ì—… ê³„íš ìˆ˜ë¦½", progress=10, details="PRD ì‘ì„± 5ë‹¨ê³„ ê³„íš ìˆ˜ë¦½ ì¤‘")
- report_progress(stage="executing", action="ê³¼ê±° ëŒ€í™” ê²€ìƒ‰", progress=30, details="ë³‘ì› ìƒì„¸ í˜ì´ì§€ ê´€ë ¨ ëŒ€í™” ê²€ìƒ‰ ì¤‘")
"""

    graph = create_agent_graph()
    initial_state = {
        "messages": [
            HumanMessage(content=system_prompt),
            HumanMessage(content=user_query)
        ],
        "progress_log": []
    }

    print("=" * 60)
    print("ğŸš€ Agent Flow ì‹œì‘ (GPT-5-mini via Direct OpenAI Client)")
    print("=" * 60)

    try:
        for event in graph.stream(initial_state):
            print(f"\nğŸ“¦ Event: {list(event.keys())}")
            
        print("\nğŸ”„ ìµœì¢… ê²°ê³¼ ì§‘ê³„ ì¤‘...")
        final_state = graph.invoke(initial_state)

        print("\n" + "=" * 60)
        print("âœ… Agent Flow ì™„ë£Œ")
        print("=" * 60)

        print("\nğŸ“‹ ì§„í–‰ ìƒí™© ìš”ì•½:")
        if "progress_log" in final_state:
            for i, log in enumerate(final_state["progress_log"], 1):
                print(f"{i}. [{log['progress']}%] {log['action']}: {log['details']}")

        print("\nğŸ’¡ ìµœì¢… ë‹µë³€:")
        if final_state["messages"]:
            print(final_state["messages"][-1].content)

        return final_state

    except Exception as e:
        print(f"\nâŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    if not os.getenv("OPENAI_API_KEY"):
        print("\nâš ï¸  OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("PowerShellì—ì„œ ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•´ì£¼ì„¸ìš”:")
        print('$env:OPENAI_API_KEY="your-api-key-here"')
        exit(1)
    
    print("\nğŸ¤– ì‚¬ìš© ëª¨ë¸: GPT-5-mini-2025-08-07 (Direct OpenAI Client)")
    print("ğŸ“š ì°¸ê³ : https://community.openai.com/t/gpt-5-models-temperature/1337957\n")
    
    run_agent_with_progress(
        "ë³‘ì› ìƒì„¸ í˜ì´ì§€ì˜ ê°„í˜¸ë“±ê¸‰ ì •ë³´ í‘œì‹œ ë°©ë²•ì— ëŒ€í•œ PRDë¥¼ ì‘ì„±í•´ì¤˜"
    )

