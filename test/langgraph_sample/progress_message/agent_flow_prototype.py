# src/ats/ax/test/langgraph_sample/agent_flow_prototype.py
"""
LangGraphë¥¼ ì‚¬ìš©í•œ Agent Flow í”„ë¡œí† íƒ€ì… (GPT-4 ë²„ì „)

âš ï¸ GPT-5 ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ agent_flow_gpt5_direct.pyë¥¼ ì‚¬ìš©í•˜ì„¸ìš”!

íŠ¹ì§•:
- OpenAI GPT-4o-mini ëª¨ë¸ ì‚¬ìš© (ì•ˆì •ì )
- ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ ë³´ê³  (report_progress tool)
- ê³¼ê±° ëŒ€í™” ê²€ìƒ‰ ë° ë¬¸ì„œ ì½ê¸° ê¸°ëŠ¥
- ìƒíƒœ ê´€ë¦¬ ë° ë„êµ¬ ì‹¤í–‰ ì¶”ì 
- LangChain ì™„ì „ í†µí•©

ì„¤ì¹˜ í•„ìš” íŒ¨í‚¤ì§€:
pip install langgraph langchain-openai langchain-core python-dotenv

í™˜ê²½ ë³€ìˆ˜:
OPENAI_API_KEY=your-api-key-here
"""

import operator
import os
from typing import TypedDict, Annotated, Sequence, List, Dict, Any, Union

# LangGraph ë° LangChain ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
try:
    from langgraph.graph import StateGraph, END
    from langgraph.prebuilt import ToolNode
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, BaseMessage
    from langchain_core.tools import tool
    from dotenv import load_dotenv
except ImportError as e:
    print("âŒ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print(f"ì˜¤ë¥˜: {e}")
    print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”: pip install langgraph langchain-openai langchain-core python-dotenv")
    exit(1)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì—ì„œ OPENAI_API_KEY ë“±ì„ ë¡œë“œ)
load_dotenv()

# ==============================================================================
# 1. State ì •ì˜ (ì‘ì—… ì§„í–‰ ìƒí™© í¬í•¨)
# ==============================================================================
class AgentState(TypedDict):
    """
    Agentì˜ ì „ì²´ ìƒíƒœë¥¼ ê´€ë¦¬í•˜ëŠ” íƒ€ì… ì •ì˜ì…ë‹ˆë‹¤.
    messages: ëŒ€í™” íˆìŠ¤í† ë¦¬ (Human, AI, Tool ë©”ì‹œì§€ ë“±)
    progress_log: ì‘ì—… ì§„í–‰ ìƒí™© ë¡œê·¸ (report_progress ë„êµ¬ì— ì˜í•´ ê¸°ë¡ë¨)
    user_request: ì‚¬ìš©ìì˜ ì›ë³¸ ìš”ì²­ (ì§„í–‰ ìƒí™© ë©”ì‹œì§€ ìƒì„± ì‹œ ì‚¬ìš©)
    """
    # operator.addëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ì´ì–´ë¶™ì´ëŠ” ë¦¬ë“€ì„œ ì—­í• ì„ í•©ë‹ˆë‹¤.
    messages: Annotated[Sequence[BaseMessage], operator.add]
    progress_log: Annotated[List[Dict[str, Any]], operator.add]
    user_request: str

# ==============================================================================
# 2. Tools ì •ì˜
# ==============================================================================

# ì •ì  ë§¤í•‘ í´ë°± ì „ëµ (LLM ìƒì„± ì‹¤íŒ¨ ì‹œ ì‚¬ìš©)
STATIC_PROGRESS_MAPPING = {
    "search_conversations": {
        "title": "ê³¼ê±° ëŒ€í™” ê²€ìƒ‰ ì¤‘",
        "description": "ê´€ë ¨ëœ ê³¼ê±° ëŒ€í™” ë‚´ì—­ì„ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤."
    },
    "read_document": {
        "title": "ë¬¸ì„œ ì½ëŠ” ì¤‘",
        "description": "ìš”ì²­í•˜ì‹  ë¬¸ì„œë¥¼ ì½ê³  ìˆìŠµë‹ˆë‹¤."
    },
    "default": {
        "title": "ì‘ì—… ì§„í–‰ ì¤‘",
        "description": "ìš”ì²­í•˜ì‹  ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤."
    }
}

def _generate_progress_message(
    user_request: str,
    tool_name: str,
    tool_description: str,
    tool_params: Dict[str, Any]
) -> Dict[str, str]:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ ìƒí™© ë©”ì‹œì§€(title, description)ë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    ìƒì„± ì‹¤íŒ¨ ì‹œ ì •ì  ë§¤í•‘ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    Args:
        user_request: ì‚¬ìš©ìì˜ ì›ë³¸ ìš”ì²­
        tool_name: í˜¸ì¶œëœ íˆ´ ì´ë¦„
        tool_description: íˆ´ ì„¤ëª…
        tool_params: íˆ´ íŒŒë¼ë¯¸í„°
    
    Returns:
        Dict[str, str]: titleê³¼ descriptionì„ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
    """
    try:
        # LLMì„ ì‚¬ìš©í•˜ì—¬ ë™ì  ìƒì„±
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0
        )
        
        prompt = f"""## Role
ì‚¬ìš©ìì—ê²Œ í˜„ì¬ AI Agentì˜ ì‘ì—… ì§„í–‰ ìƒí™©ì„ ì„¤ëª…í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

## Input
- ì‚¬ìš©ì ìš”ì²­: {user_request}
- í˜¸ì¶œ íˆ´: {tool_name}
- íˆ´ ì„¤ëª…: {tool_description}
- íˆ´ íŒŒë¼ë¯¸í„°: {tool_params}

## Output Format
title: [ì‘ì—… ë‹¨ê³„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ëª…ì‚¬í˜• ì œëª©, 15ì ë‚´ì™¸]
description: [í˜„ì¬ ìˆ˜í–‰ ì¤‘ì¸ ì‘ì—…ì„ 1~3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…. tool_paramsì˜ êµ¬ì²´ì  ê°’ì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨]

## Guidelines
- titleì€ "~ì¤‘", "~ í™•ì¸" í˜•íƒœì˜ ëª…ì‚¬í˜•
- descriptionì€ "~í•˜ê³  ìˆìŠµë‹ˆë‹¤" í˜•íƒœ
- tool_paramsì— ìˆëŠ” í‚¤ì›Œë“œ, ID, ì´ë¦„ ë“±ì„ descriptionì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ì„œ êµ¬ì²´ì„± í™•ë³´
- ê¸°ìˆ  ìš©ì–´ëŠ” ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ ë³€í™˜ (ì˜ˆ: "url_tracker" â†’ "ì œê³µí•  í˜ì´ì§€ ì°¾ëŠ” ì¤‘")

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
title: [ì œëª©]
description: [ì„¤ëª…]"""
        
        response = llm.invoke(prompt)
        content = response.content
        
        # ì‘ë‹µ íŒŒì‹±
        lines = content.strip().split('\n')
        title = ""
        description = ""
        
        for line in lines:
            if line.startswith('title:'):
                title = line.replace('title:', '').strip()
            elif line.startswith('description:'):
                description = line.replace('description:', '').strip()
        
        if title and description:
            return {
                "title": title,
                "description": description
            }
    except Exception as e:
        print(f"âš ï¸ LLM ì§„í–‰ ìƒí™© ë©”ì‹œì§€ ìƒì„± ì‹¤íŒ¨, í´ë°± ì‚¬ìš©: {e}")
    
    # í´ë°±: ì •ì  ë§¤í•‘ ì‚¬ìš©
    mapping = STATIC_PROGRESS_MAPPING.get(tool_name, STATIC_PROGRESS_MAPPING["default"])
    return {
        "title": mapping["title"],
        "description": mapping["description"]
    }

@tool
def report_progress(
    user_request: str,
    tool_name: str,
    tool_description: str,
    tool_params: Dict[str, Any]
) -> str:
    """
    ì‘ì—… ì§„í–‰ ìƒí™©ì„ ì‚¬ìš©ìì—ê²Œ ë³´ê³ í•©ë‹ˆë‹¤.
    AgentëŠ” ì¤‘ìš”í•œ ë‹¨ê³„ë§ˆë‹¤ ì´ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì—¬ ì‚¬ìš©ìì—ê²Œ í”¼ë“œë°±ì„ ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.
    
    ì´ íˆ´ì€ LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì¹œí™”ì ì¸ ì§„í–‰ ìƒí™© ë©”ì‹œì§€ë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        user_request: ì‚¬ìš©ìì˜ ì›ë³¸ ìš”ì²­
        tool_name: í˜„ì¬ í˜¸ì¶œí•˜ë ¤ëŠ” íˆ´ì˜ ì´ë¦„
        tool_description: íˆ´ì˜ ì„¤ëª…
        tool_params: íˆ´ì— ì „ë‹¬í•  íŒŒë¼ë¯¸í„° (ë”•ì…”ë„ˆë¦¬ í˜•íƒœ)
    
    Returns:
        str: ë³´ê³  ì™„ë£Œ ë©”ì‹œì§€
    """
    # ì§„í–‰ ìƒí™© ë©”ì‹œì§€ ìƒì„± (LLM ë™ì  ìƒì„± ë˜ëŠ” ì •ì  ë§¤í•‘ í´ë°±)
    progress_msg = _generate_progress_message(
        user_request=user_request,
        tool_name=tool_name,
        tool_description=tool_description,
        tool_params=tool_params
    )
    
    # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì—¬ê¸°ì„œ WebSocketì´ë‚˜ DBë¡œ ìƒíƒœë¥¼ ì „ì†¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    print(f"\nğŸ“Š {progress_msg['title']}")
    print(f"   ğŸ’¬ {progress_msg['description']}\n")

    return f"ì§„í–‰ ìƒí™©ì´ ì‚¬ìš©ìì—ê²Œ ë³´ê³ ë˜ì—ˆìŠµë‹ˆë‹¤: {progress_msg['title']}"

@tool
def search_conversations(query: str) -> str:
    """
    ê³¼ê±° ëŒ€í™” ë‚´ì—­ì´ë‚˜ í”„ë¡œì íŠ¸ íˆìŠ¤í† ë¦¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰í•  í‚¤ì›Œë“œë‚˜ ì§ˆë¬¸
        
    Returns:
        str: ê²€ìƒ‰ëœ ëŒ€í™” ìš”ì•½
    """
    # TODO: ì‹¤ì œ Vector Storeë‚˜ DB ê²€ìƒ‰ ë¡œì§ìœ¼ë¡œ êµì²´ í•„ìš”
    return f"'{query}' ê´€ë ¨ ëŒ€í™” 3ê±´ ë°œê²¬: ë³‘ì› ìƒì„¸ í˜ì´ì§€ UX, í•„í„°ë§ ì‹œìŠ¤í…œ, í”„ë¡œí•„ ì„¤ê³„"

@tool
def read_document(path: str) -> str:
    """
    ì§€ì •ëœ ê²½ë¡œì˜ ë¬¸ì„œë¥¼ ì½ì–´ì„œ ë‚´ìš©ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        path: íŒŒì¼ ê²½ë¡œ
        
    Returns:
        str: ë¬¸ì„œ ë‚´ìš©
    """
    # TODO: ì‹¤ì œ íŒŒì¼ ì‹œìŠ¤í…œ ì½ê¸° ë¡œì§ìœ¼ë¡œ êµì²´ í•„ìš”
    return f"{path} ë¬¸ì„œ ë‚´ìš© ë¡œë“œ ì™„ë£Œ"

# ==============================================================================
# 3. Nodes ì •ì˜
# ==============================================================================

def agent_node(state: AgentState):
    """
    Agent ë…¸ë“œ: LLMì„ í˜¸ì¶œí•˜ì—¬ ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•©ë‹ˆë‹¤.
    
    ì°¸ê³ : GPT-5 ì‚¬ìš© ì‹œ agent_flow_gpt5_direct.pyë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    ì´ íŒŒì¼ì€ ì•ˆì •ì ì¸ GPT-4 ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    if not os.getenv("OPENAI_API_KEY"):
        print("âš ï¸ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í˜¸ì¶œì´ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # GPT-4 ëª¨ë¸ ì‚¬ìš© (ì•ˆì •ì ì´ê³  ëª¨ë“  íŒŒë¼ë¯¸í„° ì§€ì›)
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0
    )

    # Agentê°€ ì‚¬ìš©í•  ë„êµ¬ ë°”ì¸ë”©
    tools = [report_progress, search_conversations, read_document]
    llm_with_tools = llm.bind_tools(tools)

    # í˜„ì¬ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLM í˜¸ì¶œ
    response = llm_with_tools.invoke(state["messages"])

    # ìƒˆë¡œìš´ ë©”ì‹œì§€ ë°˜í™˜ (ê¸°ì¡´ messages ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ë¨)
    return {
        "messages": [response]
    }

def tool_node(state: AgentState):
    """
    Tools ë…¸ë“œ: Agentê°€ ì„ íƒí•œ ë„êµ¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    report_progress ë„êµ¬ê°€ í˜¸ì¶œëœ ê²½ìš°, progress_log ìƒíƒœë„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    """
    tools = [report_progress, search_conversations, read_document]
    tool_executor = ToolNode(tools)

    # ë„êµ¬ ì‹¤í–‰ (ToolMessage ë°˜í™˜)
    result = tool_executor.invoke(state)

    # report_progress í˜¸ì¶œ ì—¬ë¶€ í™•ì¸ ë° ë¡œê·¸ ê¸°ë¡
    # state["messages"][-1]ì€ Agentê°€ ìƒì„±í•œ AIMessage (tool_calls í¬í•¨)
    last_message = state["messages"][-1]
    progress_entries = []
    
    if hasattr(last_message, 'tool_calls'):
        for tool_call in last_message.tool_calls:
            if tool_call['name'] == 'report_progress':
                # ì§„í–‰ ìƒí™© ë©”ì‹œì§€ ìƒì„±
                user_request = tool_call['args'].get('user_request', state.get('user_request', ''))
                tool_name = tool_call['args'].get('tool_name', '')
                tool_description = tool_call['args'].get('tool_description', '')
                tool_params = tool_call['args'].get('tool_params', {})
                
                progress_msg = _generate_progress_message(
                    user_request=user_request,
                    tool_name=tool_name,
                    tool_description=tool_description,
                    tool_params=tool_params
                )
                
                progress_entry = {
                    'title': progress_msg['title'],
                    'description': progress_msg['description']
                }
                progress_entries.append(progress_entry)
    
    output = {
        "messages": result["messages"]
    }
    
    # ì§„í–‰ ë¡œê·¸ê°€ ìˆë‹¤ë©´ ìƒíƒœì— ì¶”ê°€
    if progress_entries:
        output["progress_log"] = progress_entries

    return output

# ==============================================================================
# 4. Graph êµ¬ì„±
# ==============================================================================

def should_continue(state: AgentState):
    """
    ì¡°ê±´ë¶€ ì—£ì§€: ë„êµ¬ í˜¸ì¶œì´ ìˆìœ¼ë©´ Tools ë…¸ë“œë¡œ, ì—†ìœ¼ë©´ ì¢…ë£Œ.
    """
    last_message = state["messages"][-1]

    # Tool callì´ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ tools ë…¸ë“œë¡œ ì´ë™
    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        return "tools"

    # ë„êµ¬ í˜¸ì¶œì´ ì—†ë‹¤ë©´(ìµœì¢… ë‹µë³€ ìƒì„±) ì¢…ë£Œ
    return END

def create_agent_graph():
    """
    LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ìƒì„±í•˜ê³  ì»´íŒŒì¼í•©ë‹ˆë‹¤.
    """
    workflow = StateGraph(AgentState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("agent", agent_node)
    workflow.add_node("tools", tool_node)

    # ì‹œì‘ì  ì„¤ì •
    workflow.set_entry_point("agent")

    # ì—£ì§€ ì¶”ê°€
    workflow.add_conditional_edges(
        "agent",
        should_continue,
        {
            "tools": "tools",
            END: END
        }
    )

    # ë„êµ¬ ì‹¤í–‰ í›„ì—ëŠ” ë‹¤ì‹œ Agentê°€ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•˜ë„ë¡ ìˆœí™˜
    workflow.add_edge("tools", "agent")

    return workflow.compile()

# ==============================================================================
# 5. ì‹¤í–‰ ë¡œì§
# ==============================================================================

def run_agent_with_progress(user_query: str):
    """
    Agentë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    """

    # System Prompt: Agentì˜ ì—­í• ê³¼ ë³´ê³  ì˜ë¬´ë¥¼ ëª…ì‹œ
    system_prompt = """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ì¤‘ìš”**: ì‘ì—…ì„ ìˆ˜í–‰í•  ë•Œë§ˆë‹¤ report_progress ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬
ì‚¬ìš©ìì—ê²Œ ì§„í–‰ ìƒí™©ì„ ì•Œë ¤ì£¼ì„¸ìš”.

## Tool Guideline
ì‘ì—… ì‹œì‘ ì‹œ report_progress íˆ´ì„ í˜¸ì¶œí•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ì•Œë ¤ì£¼ì„¸ìš”.

ë³´ê³  ì‹œì :
1. ìƒˆë¡œìš´ ë‹¨ê³„ ì‹œì‘ ì‹œ
2. ì¤‘ìš”í•œ ë„êµ¬ í˜¸ì¶œ ì „í›„
3. ì˜ë¯¸ìˆëŠ” ê²°ê³¼ ë„ì¶œ ì‹œ

report_progress ì‚¬ìš© ì˜ˆì‹œ:
- ìš”ì²­ ë¶„ì„ ì‹œì‘: report_progress(user_request="ì‚¬ìš©ì ìš”ì²­", tool_name="search_conversations", tool_description="ê³¼ê±° ëŒ€í™” ê²€ìƒ‰", tool_params={"query": "í‚¤ì›Œë“œ"})
- ë¬¸ì„œ ì½ê¸° ì‹œì‘: report_progress(user_request="ì‚¬ìš©ì ìš”ì²­", tool_name="read_document", tool_description="ë¬¸ì„œ ì½ê¸°", tool_params={"path": "/path/to/doc"})

report_progressëŠ” ë‹¤ë¥¸ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ê¸° ì „ì— í˜¸ì¶œí•˜ì—¬ ì‚¬ìš©ìì—ê²Œ í˜„ì¬ ì‘ì—… ìƒí™©ì„ ì•Œë ¤ì£¼ì„¸ìš”.
"""

    graph = create_agent_graph()

    initial_state = {
        "messages": [
            HumanMessage(content=system_prompt),
            HumanMessage(content=user_query)
        ],
        "progress_log": [],
        "user_request": user_query
    }

    print("=" * 60)
    print("ğŸš€ Agent Flow ì‹œì‘")
    print("=" * 60)

    try:
        # ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰: ê° ë‹¨ê³„ë³„ ì´ë²¤íŠ¸ í™•ì¸
        # (ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” invokeë§Œ ì‚¬ìš©í•´ë„ ë©ë‹ˆë‹¤)
        for event in graph.stream(initial_state):
            print(f"\nğŸ“¦ Event: {list(event.keys())}")
            
        # ìµœì¢… ê²°ê³¼ ì¡°íšŒ
        # graph.stream ì™„ë£Œ í›„ ìƒíƒœë¥¼ í™•ì‹¤íˆ ì–»ê¸° ìœ„í•´ invokeë¥¼ ì‚¬ìš© (ì¤‘ë³µ ì‹¤í–‰ ê°€ëŠ¥ì„± ìˆìŒ)
        # íš¨ìœ¨ì„±ì„ ìœ„í•´ì„œëŠ” streamì˜ ë§ˆì§€ë§‰ stateë¥¼ ìº¡ì²˜í•˜ëŠ” ê²ƒì´ ì¢‹ìŒ
        print("\nğŸ”„ ìµœì¢… ê²°ê³¼ ì§‘ê³„ ì¤‘...")
        final_state = graph.invoke(initial_state)

        print("\n" + "=" * 60)
        print("âœ… Agent Flow ì™„ë£Œ")
        print("=" * 60)

        # ì§„í–‰ ë¡œê·¸ ìš”ì•½
        print("\nğŸ“‹ ì§„í–‰ ìƒí™© ìš”ì•½:")
        if "progress_log" in final_state:
            for i, log in enumerate(final_state["progress_log"], 1):
                print(f"{i}. {log.get('title', 'ì‘ì—… ì§„í–‰ ì¤‘')}")
                print(f"   {log.get('description', '')}")

        # ìµœì¢… ë‹µë³€
        print("\nğŸ’¡ ìµœì¢… ë‹µë³€:")
        if final_state["messages"]:
            print(final_state["messages"][-1].content)

        return final_state

    except Exception as e:
        print(f"\nâŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

if __name__ == "__main__":
    if not os.getenv("OPENAI_API_KEY"):
        print("\nâš ï¸  OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("PowerShellì—ì„œ ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•´ì£¼ì„¸ìš”:")
        print('$env:OPENAI_API_KEY="your-api-key-here"')
        exit(1)
    
    print("\n" + "=" * 60)
    print("ğŸ¤– ì‚¬ìš© ëª¨ë¸: GPT-4o-mini (ì•ˆì • ë²„ì „)")
    print("ğŸ“ GPT-5ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´: python agent_flow_gpt5_direct.py")
    print("=" * 60 + "\n")
    
    # ì •ì±… ë¬¸ì„œ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤
    test_scenarios = [
        "ê¸°ì¡´ ì±„ìš©ì„ ë¶ˆëŸ¬ì˜¤ê³  ì‹¶ì–´",  # ê¸°ì¡´ ì±„ìš© ë¶ˆëŸ¬ì˜¤ê¸°
        # "ê³µì±„ ì±„ìš©ì„ ìƒì„±í•˜ê³  ì‹¶ì–´",  # ê³µì±„ ì±„ìš© ìƒì„±
        # "ìˆ˜ìƒì‹œ ì±„ìš©ì„ ìƒì„±í•˜ê³  ì‹¶ì–´",  # ìˆ˜ìƒì‹œ ì±„ìš© ìƒì„±
    ]
    
    # ì²« ë²ˆì§¸ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
    run_agent_with_progress(test_scenarios[0])
    
    # ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”
    # for scenario in test_scenarios:
    #     print("\n" + "=" * 60)
    #     print(f"ğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸: {scenario}")
    #     print("=" * 60 + "\n")
    #     run_agent_with_progress(scenario)

