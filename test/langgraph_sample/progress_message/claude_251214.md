ë„¤, LangGraphë¡œ ì™„ì „íˆ ê°€ëŠ¥í•©ë‹ˆë‹¤! ì˜¤íˆë ¤ LangGraphê°€ ì´ëŸ° ìš©ë„ì— **ìµœì í™”ëœ í”„ë ˆì„ì›Œí¬**ì…ë‹ˆë‹¤.

## LangGraphê°€ ì í•©í•œ ì´ìœ 

```
LangGraph = Agent ìƒíƒœ ê´€ë¦¬ + ë„êµ¬ ì‹¤í–‰ + ì§„í–‰ ìƒí™© ì¶”ì 
```

íŠ¹íˆ LangGraphì˜ **StateGraph**ì™€ **streaming** ê¸°ëŠ¥ì´ ë”± ë§ìŠµë‹ˆë‹¤.

## ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… êµ¬í˜„

### 1. ì„¤ì¹˜

```bash
pip install langgraph langchain-anthropic python-dotenv
```

### 2. ê¸°ë³¸ êµ¬ì¡°

```python
# agent_flow_prototype.py
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from typing import TypedDict, Annotated, Sequence
import operator

# 1. State ì •ì˜ (ì‘ì—… ì§„í–‰ ìƒí™© í¬í•¨)
class AgentState(TypedDict):
    messages: Annotated[Sequence[HumanMessage | AIMessage | ToolMessage], operator.add]
    progress_log: Annotated[list[dict], operator.add]  # ì§„í–‰ ìƒí™© ë¡œê·¸

# 2. Progress Reporting Tool
from langchain_core.tools import tool

@tool
def report_progress(
    stage: str,
    action: str,
    progress: int,
    details: str
) -> str:
    """
    ì‘ì—… ì§„í–‰ ìƒí™©ì„ ì‚¬ìš©ìì—ê²Œ ë³´ê³ í•©ë‹ˆë‹¤.

    Args:
        stage: í˜„ì¬ ì‘ì—… ë‹¨ê³„ (planning/executing/analyzing/finalizing)
        action: ìˆ˜í–‰ ì¤‘ì¸ êµ¬ì²´ì  ì‘ì—…
        progress: ì „ì²´ ì§„í–‰ë¥  (0-100)
        details: ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ìƒì„¸ ë©”ì‹œì§€
    """
    print(f"\nğŸ“Š [{progress}%] {stage.upper()}: {action}")
    print(f"   ğŸ’¬ {details}\n")

    return f"ì§„í–‰ ìƒí™©ì´ ì‚¬ìš©ìì—ê²Œ ë³´ê³ ë˜ì—ˆìŠµë‹ˆë‹¤: {action} ({progress}%)"

# 3. ë‹¤ë¥¸ ë„êµ¬ë“¤ (ì˜ˆì‹œ)
@tool
def search_conversations(query: str) -> str:
    """ê³¼ê±° ëŒ€í™”ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    # ì‹¤ì œë¡œëŠ” conversation_search í˜¸ì¶œ
    return f"'{query}' ê´€ë ¨ ëŒ€í™” 3ê±´ ë°œê²¬: ë³‘ì› ìƒì„¸ í˜ì´ì§€ UX, í•„í„°ë§ ì‹œìŠ¤í…œ, í”„ë¡œí•„ ì„¤ê³„"

@tool
def read_document(path: str) -> str:
    """ë¬¸ì„œë¥¼ ì½ìŠµë‹ˆë‹¤."""
    # ì‹¤ì œë¡œëŠ” view tool í˜¸ì¶œ
    return f"{path} ë¬¸ì„œ ë‚´ìš© ë¡œë“œ ì™„ë£Œ"

# 4. Agent ë…¸ë“œ ì •ì˜
def agent_node(state: AgentState):
    """LLMì´ ë‹¤ìŒ í–‰ë™ì„ ê²°ì •"""
    llm = ChatAnthropic(
        model="claude-sonnet-4-20250514",
        temperature=0
    )

    # Tool ë°”ì¸ë”©
    tools = [report_progress, search_conversations, read_document]
    llm_with_tools = llm.bind_tools(tools)

    # LLM í˜¸ì¶œ
    response = llm_with_tools.invoke(state["messages"])

    return {
        "messages": [response]
    }

# 5. Tool ì‹¤í–‰ ë…¸ë“œ
def tool_node(state: AgentState):
    """ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥"""
    tools = [report_progress, search_conversations, read_document]
    tool_executor = ToolNode(tools)

    result = tool_executor.invoke(state)

    # report_progress í˜¸ì¶œ ì‹œ ë¡œê·¸ ì €ì¥
    last_message = state["messages"][-1]
    if hasattr(last_message, 'tool_calls'):
        for tool_call in last_message.tool_calls:
            if tool_call['name'] == 'report_progress':
                progress_entry = {
                    'stage': tool_call['args']['stage'],
                    'action': tool_call['args']['action'],
                    'progress': tool_call['args']['progress'],
                    'details': tool_call['args']['details']
                }
                return {
                    "messages": result["messages"],
                    "progress_log": [progress_entry]
                }

    return result

# 6. ë¼ìš°íŒ… ë¡œì§
def should_continue(state: AgentState):
    """ë‹¤ìŒì— ë„êµ¬ë¥¼ ì‹¤í–‰í• ì§€, ì¢…ë£Œí• ì§€ ê²°ì •"""
    last_message = state["messages"][-1]

    # Tool callì´ ìˆìœ¼ë©´ ê³„ì†
    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        return "tools"

    # ì—†ìœ¼ë©´ ì¢…ë£Œ
    return END

# 7. Graph êµ¬ì„±
def create_agent_graph():
    workflow = StateGraph(AgentState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("agent", agent_node)
    workflow.add_node("tools", tool_node)

    # ì‹œì‘ì  ì„¤ì •
    workflow.set_entry_point("agent")

    # ì—£ì§€ ì¶”ê°€
    workflow.add_conditional_edges(
        "agent",
        should_continue,
        {
            "tools": "tools",
            END: END
        }
    )

    # ë„êµ¬ ì‹¤í–‰ í›„ ë‹¤ì‹œ agentë¡œ
    workflow.add_edge("tools", "agent")

    return workflow.compile()

# 8. ì‹¤í–‰ í•¨ìˆ˜
def run_agent_with_progress(user_query: str):
    """Agentë¥¼ ì‹¤í–‰í•˜ê³  ì§„í–‰ ìƒí™©ì„ ì¶œë ¥"""

    # System prompt (ì§„í–‰ ë³´ê³  ê°•ì¡°)
    system_prompt = """
ë‹¹ì‹ ì€ ë©”ë””ì»¬ì¡ë‹¤ í”„ë¡œë•íŠ¸ ë§¤ë‹ˆì €ì˜ ì—…ë¬´ë¥¼ ë•ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ì¤‘ìš”**: ì‘ì—…ì„ ìˆ˜í–‰í•  ë•Œë§ˆë‹¤ report_progress ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬
ì‚¬ìš©ìì—ê²Œ ì§„í–‰ ìƒí™©ì„ ì•Œë ¤ì£¼ì„¸ìš”.

ë³´ê³  ì‹œì :
1. ìƒˆë¡œìš´ ë‹¨ê³„ ì‹œì‘ ì‹œ
2. ì¤‘ìš”í•œ ë„êµ¬ í˜¸ì¶œ ì „í›„
3. ì˜ë¯¸ìˆëŠ” ê²°ê³¼ ë„ì¶œ ì‹œ

ì˜ˆì‹œ:
- report_progress(stage="planning", action="ì‘ì—… ê³„íš ìˆ˜ë¦½", progress=10, details="PRD ì‘ì„± 5ë‹¨ê³„ ê³„íš ìˆ˜ë¦½ ì¤‘")
- report_progress(stage="executing", action="ê³¼ê±° ëŒ€í™” ê²€ìƒ‰", progress=30, details="ë³‘ì› ìƒì„¸ í˜ì´ì§€ ê´€ë ¨ ëŒ€í™” ê²€ìƒ‰ ì¤‘")
"""

    graph = create_agent_graph()

    initial_state = {
        "messages": [
            HumanMessage(content=system_prompt),
            HumanMessage(content=user_query)
        ],
        "progress_log": []
    }

    print("=" * 60)
    print("ğŸš€ Agent Flow ì‹œì‘")
    print("=" * 60)

    # Streamingìœ¼ë¡œ ì‹¤í–‰
    for event in graph.stream(initial_state):
        print(f"\nğŸ“¦ Event: {list(event.keys())}")
        # ì‹¤ì‹œê°„ ìƒíƒœ ë³€í™”ë¥¼ ë³¼ ìˆ˜ ìˆìŒ

    # ìµœì¢… ìƒíƒœ
    final_state = graph.invoke(initial_state)

    print("\n" + "=" * 60)
    print("âœ… Agent Flow ì™„ë£Œ")
    print("=" * 60)

    # ì§„í–‰ ë¡œê·¸ ìš”ì•½
    print("\nğŸ“‹ ì§„í–‰ ìƒí™© ìš”ì•½:")
    for i, log in enumerate(final_state["progress_log"], 1):
        print(f"{i}. [{log['progress']}%] {log['action']}: {log['details']}")

    # ìµœì¢… ë‹µë³€
    print("\nğŸ’¡ ìµœì¢… ë‹µë³€:")
    print(final_state["messages"][-1].content)

    return final_state

# 9. ì‹¤í–‰
if __name__ == "__main__":
    run_agent_with_progress(
        "ë³‘ì› ìƒì„¸ í˜ì´ì§€ì˜ ê°„í˜¸ë“±ê¸‰ ì •ë³´ í‘œì‹œ ë°©ë²•ì— ëŒ€í•œ PRDë¥¼ ì‘ì„±í•´ì¤˜"
    )
```

## ì‹¤í–‰ ì˜ˆì‹œ

```bash
python agent_flow_prototype.py
```

**ì¶œë ¥:**

```
============================================================
ğŸš€ Agent Flow ì‹œì‘
============================================================

ğŸ“Š [5%] PLANNING: ì‘ì—… ê³„íš ìˆ˜ë¦½
   ğŸ’¬ PRD ì‘ì„±ì„ ìœ„í•œ 5ë‹¨ê³„ ì‘ì—… ê³„íš ìˆ˜ë¦½ ì¤‘

ğŸ“Š [15%] EXECUTING: ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
   ğŸ’¬ ê´€ë ¨ ê³¼ê±° ëŒ€í™” ë° ë¬¸ì„œ ê²€ìƒ‰ ì‹œì‘

ğŸ“Š [30%] EXECUTING: ê³¼ê±° ëŒ€í™” ê²€ìƒ‰ ì™„ë£Œ
   ğŸ’¬ 'ë³‘ì› ìƒì„¸ í˜ì´ì§€' ê´€ë ¨ ëŒ€í™” 3ê±´ ë°œê²¬

ğŸ“Š [50%] ANALYZING: ìš”êµ¬ì‚¬í•­ ë¶„ì„
   ğŸ’¬ ê°„í˜¸ë“±ê¸‰ í‘œì‹œ ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì¤‘

ğŸ“Š [75%] EXECUTING: PRD ì‘ì„±
   ğŸ’¬ PRD ì´ˆì•ˆ ì‘ì„± ì¤‘...

ğŸ“Š [100%] FINALIZING: ì™„ë£Œ
   ğŸ’¬ PRD ì‘ì„± ì™„ë£Œ ë° ê²€í†  ì™„ë£Œ

============================================================
âœ… Agent Flow ì™„ë£Œ
============================================================

ğŸ“‹ ì§„í–‰ ìƒí™© ìš”ì•½:
1. [5%] ì‘ì—… ê³„íš ìˆ˜ë¦½: PRD ì‘ì„±ì„ ìœ„í•œ 5ë‹¨ê³„ ì‘ì—… ê³„íš ìˆ˜ë¦½ ì¤‘
2. [15%] ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘: ê´€ë ¨ ê³¼ê±° ëŒ€í™” ë° ë¬¸ì„œ ê²€ìƒ‰ ì‹œì‘
3. [30%] ê³¼ê±° ëŒ€í™” ê²€ìƒ‰ ì™„ë£Œ: 'ë³‘ì› ìƒì„¸ í˜ì´ì§€' ê´€ë ¨ ëŒ€í™” 3ê±´ ë°œê²¬
...
```

## ë” ê°œì„ ëœ ë²„ì „: ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°

```python
# agent_flow_streaming.py
from langgraph.graph import StateGraph
from langchain_core.runnables import RunnableConfig
import asyncio

async def run_agent_with_streaming(user_query: str):
    """ì‹¤ì‹œê°„ìœ¼ë¡œ ì§„í–‰ ìƒí™©ì„ ìŠ¤íŠ¸ë¦¬ë°"""

    graph = create_agent_graph()

    initial_state = {
        "messages": [HumanMessage(content=user_query)],
        "progress_log": []
    }

    print("ğŸ¬ Agent ì‹¤í–‰ ì‹œì‘...\n")

    # astream_eventsë¥¼ ì‚¬ìš©í•˜ë©´ ë” ì„¸ë°€í•œ ì œì–´ ê°€ëŠ¥
    async for event in graph.astream_events(
        initial_state,
        version="v1"
    ):
        kind = event["event"]

        # Tool ì‹¤í–‰ ì‹œì‘
        if kind == "on_tool_start":
            tool_name = event["name"]
            print(f"ğŸ”§ ë„êµ¬ ì‹¤í–‰: {tool_name}")

        # Tool ì‹¤í–‰ ì™„ë£Œ
        elif kind == "on_tool_end":
            tool_name = event["name"]
            print(f"âœ… ë„êµ¬ ì™„ë£Œ: {tool_name}")

        # LLM ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
        elif kind == "on_chat_model_stream":
            content = event["data"]["chunk"].content
            if content:
                print(content, end="", flush=True)

# ì‹¤í–‰
asyncio.run(run_agent_with_streaming(
    "ë³‘ì› ìƒì„¸ í˜ì´ì§€ PRD ì‘ì„±í•´ì¤˜"
))
```

## ì›¹ UI ë²„ì „ (FastAPI + LangGraph)

```python
# server.py
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from langgraph.graph import StateGraph
import json

app = FastAPI()

@app.get("/agent/stream")
async def agent_stream(query: str):
    """SSEë¡œ ì§„í–‰ ìƒí™© ìŠ¤íŠ¸ë¦¬ë°"""

    async def event_generator():
        graph = create_agent_graph()
        initial_state = {
            "messages": [HumanMessage(content=query)],
            "progress_log": []
        }

        async for event in graph.astream_events(initial_state, version="v1"):
            # ì§„í–‰ ìƒí™©ì„ JSONìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì „ì†¡
            yield f"data: {json.dumps(event)}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )

# ì‹¤í–‰: uvicorn server:app --reload
```

```html
<!-- frontend.html -->
<!DOCTYPE html>
<html>
  <body>
    <div id="progress"></div>

    <script>
      const eventSource = new EventSource("/agent/stream?query=PRDì‘ì„±");

      eventSource.onmessage = (event) => {
        const data = JSON.parse(event.data);

        if (data.event === "on_tool_start") {
          document.getElementById(
            "progress"
          ).innerHTML += `<p>ğŸ”§ ${data.name} ì‹¤í–‰ ì¤‘...</p>`;
        }

        if (data.name === "report_progress") {
          const args = data.data.input;
          document.getElementById(
            "progress"
          ).innerHTML += `<p>[${args.progress}%] ${args.action}: ${args.details}</p>`;
        }
      };
    </script>
  </body>
</html>
```

## LangGraphì˜ ê°•ë ¥í•œ ê¸°ëŠ¥ë“¤

### 1. ìƒíƒœ ìŠ¤ëƒ…ìƒ· (Checkpointing)

```python
from langgraph.checkpoint.memory import MemorySaver

# ì§„í–‰ ìƒí™©ì„ ì €ì¥í•˜ê³  ë³µêµ¬ ê°€ëŠ¥
checkpointer = MemorySaver()
graph = workflow.compile(checkpointer=checkpointer)

# ì‹¤í–‰ ì¤‘ ì–¸ì œë“  ìƒíƒœ í™•ì¸
config = {"configurable": {"thread_id": "1"}}
state = graph.get_state(config)
print(state.values["progress_log"])
```

### 2. Human-in-the-Loop

```python
# íŠ¹ì • ë‹¨ê³„ì—ì„œ ì‚¬ìš©ì í™•ì¸ ë°›ê¸°
def needs_approval(state):
    return "approval_needed"

workflow.add_conditional_edges(
    "agent",
    needs_approval,
    {
        "approval_needed": "wait_for_human",
        "continue": "tools"
    }
)
```

### 3. ì‹œê°í™”

```python
from IPython.display import Image, display

# Graph êµ¬ì¡° ì‹œê°í™”
display(Image(graph.get_graph().draw_mermaid_png()))
```

## ë©”ë””ì»¬ì¡ë‹¤ ì‹¤ì „ ì˜ˆì œ

```python
# medical_jobda_agent.py
@tool
def analyze_hospital_data(hospital_name: str) -> str:
    """ë³‘ì› ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    # ì‹¤ì œë¡œëŠ” ì—…ë¡œë“œëœ ë¬¸ì„œì—ì„œ ë°ì´í„° ì¶”ì¶œ
    return f"{hospital_name}ì˜ ê°„í˜¸ë“±ê¸‰, ë³‘ìƒ ìˆ˜ ë“± ë°ì´í„° ë¶„ì„ ì™„ë£Œ"

@tool
def create_prd_document(content: dict) -> str:
    """PRD ë¬¸ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    # create_file tool ì‚¬ìš©
    return "PRD ë¬¸ì„œ ìƒì„± ì™„ë£Œ: /outputs/hospital_detail_prd.md"

def medical_jobda_agent(query: str):
    """ë©”ë””ì»¬ì¡ë‹¤ íŠ¹í™” Agent"""

    system_prompt = """
ë‹¹ì‹ ì€ ë©”ë””ì»¬ì¡ë‹¤ì˜ PM ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‘ì—… ì§„í–‰ ì‹œ ë°˜ë“œì‹œ report_progressë¥¼ ìì£¼ í˜¸ì¶œí•˜ì„¸ìš”:
- ë°ì´í„° ë¶„ì„ ì‹œì‘/ì™„ë£Œ
- ë¬¸ì„œ ê²€ìƒ‰ ì‹œì‘/ì™„ë£Œ
- PRD ì‘ì„± ë‹¨ê³„ë³„ ì§„í–‰

ì˜ë£Œ ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ê°„í˜¸ì‚¬ ì±„ìš© ì‹œì¥ì˜ ë§¥ë½ì—ì„œ ë‹µë³€í•˜ì„¸ìš”.
"""

    # ... (ìœ„ì™€ ë™ì¼í•œ êµ¬ì¡°)
```

## ë‹¤ìŒ ë‹¨ê³„: Spring AIë¡œ ì´ì‹

LangGraphì—ì„œ ê²€ì¦í•œ ë¡œì§ì„ Spring AIë¡œ ì˜®ê¸°ê¸°:

```java
// Spring AI ë²„ì „ (ì°¸ê³ ìš©)
@Service
public class AgentFlowService {

    @Autowired
    private ChatClient chatClient;

    @Autowired
    private SseEmitter emitter;

    public void executeWithProgress(String query) {
        // 1. Tool ì •ì˜
        var reportProgress = FunctionCallback.builder()
            .function("report_progress", this::reportProgress)
            .description("ì§„í–‰ ìƒí™© ë³´ê³ ")
            .build();

        // 2. Chat ì‹¤í–‰
        chatClient.prompt()
            .user(query)
            .functions(reportProgress, searchConversations, readDocument)
            .stream()
            .content()
            .subscribe(chunk -> {
                emitter.send(chunk);
            });
    }

    private String reportProgress(ProgressRequest request) {
        // SSEë¡œ ì§„í–‰ ìƒí™© ì „ì†¡
        emitter.send(SseEmitter.event()
            .name("progress")
            .data(request));

        return "ì§„í–‰ ìƒí™© ë³´ê³  ì™„ë£Œ";
    }
}
```

## ê²°ë¡ 

âœ… **LangGraphë¡œ ì™„ì „íˆ êµ¬í˜„ ê°€ëŠ¥**
âœ… **Pythonìœ¼ë¡œ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… ì œì‘**
âœ… **ê²€ì¦ í›„ Spring AIë¡œ ì´ì‹**

ìœ„ ì½”ë“œë¥¼ ë³µì‚¬í•´ì„œ ë°”ë¡œ ì‹¤í–‰í•´ë³´ì‹œê³ , ê¶ê¸ˆí•œ ì  ìˆìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”!
